{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_style('whitegrid')\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import urlparse, quote, unquote\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# requires pip install tldextract\n",
    "#import tldextract\n",
    "\n",
    "import networkx as nx \n",
    "import time, os, re\n",
    "\n",
    "_dir = 'E:/Dropbox/Workspace/Wikipedia_Trump/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/a/312464/1574687\n",
    "\n",
    "def chunk_list(l,size=50): \n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    chunk_list = list()\n",
    "    for i in range(0, len(l), size):\n",
    "        chunk_list.append(l[i:i + size])\n",
    "    return chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,712 bots.\n"
     ]
    }
   ],
   "source": [
    "with open('bots.json','r') as f:\n",
    "    bot_list = json.load(f)\n",
    "    \n",
    "bot_list = [name[5:] for name in bot_list]\n",
    "print(\"There are {0:,} bots.\".format(len(bot_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_revisions(page_title,lang='en'):\n",
    "    \"\"\"Takes Wikipedia page title and returns a DataFrame of revisions\n",
    "    \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "        \n",
    "    Returns:\n",
    "    revision_list - a list of dictionaries, where each dictionary is the revision\n",
    "        meta-data such as parentid, revid,sha1, size, timestamp, and user name\n",
    "    \"\"\"\n",
    "    \n",
    "    revision_list = list()\n",
    "    \n",
    "    query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&titles={0}&prop=revisions&rvprop=ids|userid|comment|timestamp|user|size|sha1&rvlimit=500&rvdir=older&format=json&formatversion=2\".format(page_title,lang)\n",
    "    json_response = requests.get(query_string).json()\n",
    "    subquery_revision_list = json_response['query']['pages'][0]['revisions']\n",
    "    revision_list += subquery_revision_list\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        if 'continue' not in json_response:\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            query_continue = json_response['continue']['rvcontinue']\n",
    "            query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&titles={0}&prop=revisions&rvprop=ids|timestamp|user|size|sha1&rvlimit=500&rvcontinue={2}&rvdir=older&format=json&formatversion=2\".format(page_title,lang,query_continue)\n",
    "            json_response = requests.get(query_string).json()\n",
    "            subquery_revision_list = json_response['query']['pages'][0]['revisions']\n",
    "            revision_list += subquery_revision_list\n",
    "            #time.sleep(1)\n",
    "    \n",
    "    df = pd.DataFrame(revision_list)\n",
    "    df['page'] = page_title\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].apply(lambda x:x.date())\n",
    "    df['userid'] = df['userid'].fillna(0).apply(lambda x:str(int(x)))\n",
    "    #df['lang'] = lang\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_contributions(username,lang='en',start=pd.Timestamp('2015-01-01'),stop=pd.Timestamp('2017-11-09'),skip_power=True):\n",
    "    \"\"\"Takes Wikipedia username and returns a DataFrame of revisions\n",
    "    \n",
    "    username - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "    start - a datetime or Timestamp for the earliest user contributions to retrieve\n",
    "    stop - a datetime or Timestamp for the latest user contributions to retrieve\n",
    "    skip_power = If True, skips users who made more than 500 edits in a month\n",
    "        \n",
    "    Returns:\n",
    "    revision_list - a DataFrame containing the revision meta-data such as \n",
    "        parentid, revid,sha1, size, timestamp, and user name\n",
    "        \n",
    "    API endpoint docs: https://www.mediawiki.org/wiki/API:Usercontribs\n",
    "    \"\"\"\n",
    "    \n",
    "    start_utc = datetime.strftime(start, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    stop_utc = datetime.strftime(stop, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    \n",
    "    revision_list = list()\n",
    "    \n",
    "    query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&list=usercontribs&ucuser={0}&ucprop=ids|title|comment|timestamp|flags|size|sizediff&ucstart={2}&ucstop={3}&uclimit=500&ucdir=newer&format=json&formatversion=2\".format(username,lang,start_utc,stop_utc)\n",
    "    json_response = requests.get(query_string).json()\n",
    "    subquery_revision_list = json_response['query']['usercontribs']\n",
    "    \n",
    "    # If the first 500 edits took place in less than 30 days, we've got ourselves a power user, bot, or cyborg\n",
    "    earliest_first_500 = pd.to_datetime(json_response['query']['usercontribs'][0]['timestamp'])\n",
    "    latest_first_500 = pd.to_datetime(json_response['query']['usercontribs'][-1]['timestamp'])\n",
    "    days_elapsed_first_500 = latest_first_500 - earliest_first_500\n",
    "    \n",
    "    if len(subquery_revision_list) == 500 and days_elapsed_first_500 > np.timedelta64(30,'D'):\n",
    "    \n",
    "        revision_list += subquery_revision_list\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if 'continue' not in json_response:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                query_continue = json_response['continue']['uccontinue']\n",
    "                query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&list=usercontribs&ucuser={0}&ucprop=ids|title|comment|timestamp|flags|size|sizediff&ucstart={2}&ucstop={3}&uclimit=500&ucdir=newer&uccontinue={4}&format=json&formatversion=2\".format(username,lang,start_utc,stop_utc,query_continue)\n",
    "                json_response = requests.get(query_string).json()\n",
    "                subquery_revision_list = json_response['query']['usercontribs']\n",
    "                revision_list += subquery_revision_list\n",
    "                #time.sleep(1)\n",
    "    \n",
    "    elif 'continue' not in json_response:\n",
    "        \n",
    "        revision_list += subquery_revision_list\n",
    "        \n",
    "    df = pd.DataFrame(revision_list)\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].apply(lambda x:x.date())\n",
    "    df['userid'] = df['userid'].fillna(0).apply(lambda x:str(int(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_info(username_list,lang='en'):\n",
    "    \"\"\"Takes a list of Wikipedia usernames and returns a JSON of their information\n",
    "    \n",
    "    username_list - a list of strings for all the usernames\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "        \n",
    "    Returns:\n",
    "    users_info - a list of information about users\n",
    "    \n",
    "    API endpoint docs: https://www.mediawiki.org/wiki/API:Users\n",
    "    \"\"\"\n",
    "    users_info = []\n",
    "    \n",
    "    chunked_username_list = chunk_list(username_list)\n",
    "    \n",
    "    for chunk in chunked_username_list:\n",
    "        usernames = '|'.join(chunk)\n",
    "        query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&list=users&ususers={0}&usprop=blockinfo|groups|editcount|registration|gender&format=json&formatversion=2\".format(usernames,lang)\n",
    "        json_response = requests.get(query_string).json()\n",
    "        if 'query' in json_response:\n",
    "            users_info += json_response['query']['users']\n",
    "    \n",
    "    return users_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interlanguage_links(page_title,lang='en'):\n",
    "    \"\"\"The function accepts a page_title and returns a dictionary containing \n",
    "    the title of the page in its other languages\n",
    "       \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition, \n",
    "        defaults to \"en\"\n",
    "       \n",
    "    Returns:\n",
    "    langlink_dict - a dictionary keyed by lang codes and page title as values\n",
    "    \"\"\"\n",
    "    \n",
    "    query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&format=json&prop=langlinks&formatversion=2&titles={0}&llprop=autonym|langname&lllimit=500\".format(page_title,lang)\n",
    "    json_response = requests.get(query_string).json()\n",
    "    \n",
    "    interlanguage_link_dict = dict()\n",
    "    interlanguage_link_dict['en'] = page_title\n",
    "\n",
    "    if 'langlinks' in json_response['query']['pages'][0]:\n",
    "        langlink_dict = json_response['query']['pages'][0]['langlinks']\n",
    "\n",
    "        for d in langlink_dict:\n",
    "            lang = d['lang']\n",
    "            title = d['title']\n",
    "            interlanguage_link_dict[lang] = title\n",
    "            \n",
    "    return interlanguage_link_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interlanguage_revisions(page_title,lang='en'):\n",
    "    \"\"\"Takes a Wikipedia page title and return the interlanguage revision history\n",
    "    \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "    \n",
    "    Returns:\n",
    "    extlinks_per_lang - a dictionary keyed by language returning a dictionary\n",
    "        keyed by page title returning a Counter dictionary of external links'\n",
    "        top-level domains and counts\n",
    "    \"\"\"\n",
    "    revisions_df_dict = {}\n",
    "\n",
    "    language_titles = get_interlanguage_links(page_title,lang)\n",
    "\n",
    "    for lang,title in language_titles.items():\n",
    "        try:\n",
    "            revisions_df_dict[lang] = get_page_revisions(title,lang)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "            \n",
    "        except:\n",
    "            print(\"Error getting revisions in {0} version of \\\"{1}\\\"\".format(lang,title))\n",
    "            pass\n",
    "    \n",
    "    concat_df = pd.concat(revisions_df_dict.values(),keys=revisions_df_dict.keys(),\n",
    "                          names=['lang','rev_num']).reset_index()\n",
    "    \n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rev_externallinks(revid,lang='en',redirects=1):\n",
    "    \"\"\"Takes a revision id and returns a list of external links on the revision\n",
    "    \n",
    "    revid - a numeric revision id as a string\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language \n",
    "        edition, defaults to \"en\"\n",
    "    redirects - 1 or 0 for whether to follow page redirects, defaults to 1\n",
    "    parse - 1 or 0 for whether to return the raw HTML or paragraph text\n",
    "    \n",
    "    Returns:\n",
    "    str - a list of strings with the URLs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the response from the API for a query\n",
    "    # After passing a page title, the API returns the HTML markup of the current article version within a JSON payload\n",
    "    req = requests.get('https://{2}.wikipedia.org/w/api.php?action=parse&format=json&oldid={0}&redirects={1}&prop=externallinks&disableeditsection=1&disabletoc=1'.format(revid,redirects,lang))\n",
    "    \n",
    "    # Read the response into JSON to parse and extract the HTML\n",
    "    json_string = json.loads(req.text)\n",
    "    \n",
    "    if 'parse' in json_string.keys():\n",
    "        if 'externallinks' in json_string['parse']:\n",
    "            return json_string['parse']['externallinks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.nbc.com/nbc/The_Apprentice/bios/Donald_J._Trump.html',\n",
       " 'http://www.trumponline.com',\n",
       " 'http://www.trump.com',\n",
       " 'http://www.askmen.com/men/business_politics/38_donald_trump.html',\n",
       " 'http://www.who2.com/donaldtrump.html',\n",
       " 'http://www.bad-bad.com/gesch/d_trump.htm',\n",
       " 'http://www.rasscass.com/templ/te_bio.php?PID=187&RID=1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rev_externallinks('3953165')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rev_content(revid,lang='en',redirects=1,parsed_text=1):\n",
    "    \"\"\"Takes a revision id and returns a (large) string of the HTML content \n",
    "    of the revision.\n",
    "    \n",
    "    revid - a numeric revision id as a string\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language \n",
    "        edition, defaults to \"en\"\n",
    "    redirects - 1 or 0 for whether to follow page redirects, defaults to 1\n",
    "    parse - 1 or 0 for whether to return the raw HTML or paragraph text\n",
    "    \n",
    "    Returns:\n",
    "    str - a (large) string of the content of the revision\n",
    "    \"\"\"\n",
    "    \n",
    "    bad_titles = ['Special:','Wikipedia:','Help:','Template:','Category:','International Standard','Portal:','s:','File:','Digital object identifier','(page does not exist)']\n",
    "    \n",
    "    # Get the response from the API for a query\n",
    "    # After passing a page title, the API returns the HTML markup of the current article version within a JSON payload\n",
    "    req = requests.get('https://{2}.wikipedia.org/w/api.php?action=parse&format=json&oldid={0}&redirects={1}&prop=text&disableeditsection=1&disabletoc=1'.format(revid,redirects,lang))\n",
    "    \n",
    "    # Read the response into JSON to parse and extract the HTML\n",
    "    json_string = json.loads(req.text)\n",
    "    \n",
    "    if 'parse' in json_string.keys():\n",
    "        page_html = json_string['parse']['text']['*']\n",
    "\n",
    "        # Parse the HTML into Beautiful Soup\n",
    "        soup = BeautifulSoup(page_html,'lxml')\n",
    "        \n",
    "        # Remove sections at end\n",
    "        bad_sections = ['See_also','Notes','References','Bibliography','External_links']\n",
    "        sections = soup.find_all('h2')\n",
    "        for section in sections:\n",
    "            if section.span['id'] in bad_sections:\n",
    "                \n",
    "                # Clean out the divs\n",
    "                div_siblings = section.find_next_siblings('div')\n",
    "                for sibling in div_siblings:\n",
    "                    sibling.clear()\n",
    "                    \n",
    "                # Clean out the ULs\n",
    "                ul_siblings = section.find_next_siblings('ul')\n",
    "                for sibling in ul_siblings:\n",
    "                    sibling.clear()\n",
    "        \n",
    "        # Get all the paragraphs\n",
    "        paras = soup.find_all('p')\n",
    "        \n",
    "        text_list = []\n",
    "        \n",
    "        for para in paras:\n",
    "            if parsed_text:\n",
    "                _s = para.text\n",
    "                # Remove the citations\n",
    "                _s = re.sub(r'\\[[0-9]+\\]','',_s)\n",
    "                text_list.append(_s)\n",
    "            else:\n",
    "                text_list.append(str(para))\n",
    "        \n",
    "        return '\\n'.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rev_markup(revid,lang='en',redirects=1,parsed_text=1):\n",
    "    \"\"\"Takes a revision id and returns a (large) string of the HTML content \n",
    "    of the revision.\n",
    "    \n",
    "    revid - a numeric revision id as a string\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language \n",
    "        edition, defaults to \"en\"\n",
    "    redirects - 1 or 0 for whether to follow page redirects, defaults to 1\n",
    "    parse - 1 or 0 for whether to return the raw HTML or paragraph text\n",
    "    \n",
    "    Returns:\n",
    "    str - a (large) string of the content of the revision\n",
    "    \"\"\"\n",
    "    \n",
    "    bad_titles = ['Special:','Wikipedia:','Help:','Template:','Category:','International Standard','Portal:','s:','File:','Digital object identifier','(page does not exist)']\n",
    "    \n",
    "    # Get the response from the API for a query\n",
    "    # After passing a page title, the API returns the HTML markup of the current article version within a JSON payload\n",
    "    req = requests.get('https://{2}.wikipedia.org/w/api.php?action=parse&format=json&oldid={0}&redirects={1}&prop=text&disableeditsection=1&disabletoc=1'.format(revid,redirects,lang))\n",
    "    \n",
    "    # Read the response into JSON to parse and extract the HTML\n",
    "    json_string = json.loads(req.text)\n",
    "    \n",
    "    if 'parse' in json_string.keys():\n",
    "        page_html = json_string['parse']['text']['*']\n",
    "\n",
    "        # Parse the HTML into Beautiful Soup\n",
    "        soup = BeautifulSoup(page_html,'lxml')\n",
    "        \n",
    "        return str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rev_outlinks(revid,lang='en',redirects=1):\n",
    "    \"\"\"Takes a page title and returns a list of wiki-links on the page. The \n",
    "    list may contain duplicates and the position in the list is approximately \n",
    "    where the links occurred.\n",
    "    \n",
    "    revid - a numeric revision id as a string\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language \n",
    "        edition, defaults to \"en\"\n",
    "    redirects - 1 or 0 for whether to follow page redirects, defaults to 1\n",
    "    \n",
    "    Returns:\n",
    "    outlinks_per_lang - a dictionary keyed by language returning a dictionary \n",
    "        keyed by page title returning a list of outlinks\n",
    "    \"\"\"\n",
    "        \n",
    "    bad_titles = ['Special:','Wikipedia:','Help:','Template:','Category:','International Standard','Portal:','s:','File:','Digital object identifier','(page does not exist)']\n",
    "    \n",
    "    # Get the response from the API for a query\n",
    "    # After passing a page title, the API returns the HTML markup of the current article version within a JSON payload\n",
    "    req = requests.get('https://{2}.wikipedia.org/w/api.php?action=parse&format=json&oldid={0}&redirects={1}&prop=text&disableeditsection=1&disabletoc=1'.format(revid,redirects,lang))\n",
    "    \n",
    "    # Read the response into JSON to parse and extract the HTML\n",
    "    json_string = json.loads(req.text)\n",
    "    \n",
    "    # Initialize an empty list to store the links\n",
    "    outlinks_list = [] \n",
    "    \n",
    "    if 'parse' in json_string.keys():\n",
    "        page_html = json_string['parse']['text']['*']\n",
    "\n",
    "        # Parse the HTML into Beautiful Soup\n",
    "        soup = BeautifulSoup(page_html,'lxml')\n",
    "        \n",
    "        # Remove sections at end\n",
    "        bad_sections = ['See_also','Notes','References','Bibliography','External_links']\n",
    "        sections = soup.find_all('h2')\n",
    "        for section in sections:\n",
    "            if section.span['id'] in bad_sections:\n",
    "                \n",
    "                # Clean out the divs\n",
    "                div_siblings = section.find_next_siblings('div')\n",
    "                for sibling in div_siblings:\n",
    "                    sibling.clear()\n",
    "                    \n",
    "                # Clean out the ULs\n",
    "                ul_siblings = section.find_next_siblings('ul')\n",
    "                for sibling in ul_siblings:\n",
    "                    sibling.clear()\n",
    "\n",
    "        # Delete tags associated with templates\n",
    "        for tag in soup.find_all('tr'):\n",
    "            tag.replace_with('')\n",
    "\n",
    "        # For each paragraph tag, extract the titles within the links\n",
    "        for para in soup.find_all('p'):\n",
    "            for link in para.find_all('a'):\n",
    "                if link.has_attr('title'):\n",
    "                    title = link['title']\n",
    "                    # Ignore links that aren't interesting or are redlinks\n",
    "                    if all(bad not in title for bad in bad_titles) and 'redlink' not in link['href']:\n",
    "                        outlinks_list.append(title)\n",
    "\n",
    "        # For each unordered list, extract the titles within the child links\n",
    "        for unordered_list in soup.find_all('ul'):\n",
    "            for item in unordered_list.find_all('li'):\n",
    "                for link in item.find_all('a'):\n",
    "                    if link.has_attr('title'):\n",
    "                        title = link['title']\n",
    "                        # Ignore links that aren't interesting or are redlinks\n",
    "                        if all(bad not in title for bad in bad_titles) and 'redlink' not in link['href']:\n",
    "                            outlinks_list.append(title)\n",
    "\n",
    "    return outlinks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_outlinks(page_title,lang='en',redirects=1):\n",
    "    \"\"\"Takes a page title and returns a list of wiki-links on the page. The \n",
    "    list may contain duplicates and the position in the list is approximately \n",
    "    where the links occurred.\n",
    "    \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language \n",
    "        edition, defaults to \"en\"\n",
    "    redirects - 1 or 0 for whether to follow page redirects, defaults to 1\n",
    "    \n",
    "    Returns:\n",
    "    outlinks_per_lang - a dictionary keyed by language returning a dictionary \n",
    "        keyed by page title returning a list of outlinks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    page_title = page_title.replace(' ','_')\n",
    "    \n",
    "    bad_titles = ['Special:','Wikipedia:','Help:','Template:','Category:','International Standard','Portal:','s:','File:','Digital object identifier','(page does not exist)']\n",
    "    \n",
    "    # Get the response from the API for a query\n",
    "    # After passing a page title, the API returns the HTML markup of the current article version within a JSON payload\n",
    "    req = requests.get('https://{2}.wikipedia.org/w/api.php?action=parse&format=json&page={0}&redirects={1}&prop=text&disableeditsection=1&disabletoc=1'.format(page_title,redirects,lang))\n",
    "    \n",
    "    # Read the response into JSON to parse and extract the HTML\n",
    "    json_string = json.loads(req.text)\n",
    "    \n",
    "    # Initialize an empty list to store the links\n",
    "    outlinks_list = [] \n",
    "    \n",
    "    if 'parse' in json_string.keys():\n",
    "        page_html = json_string['parse']['text']['*']\n",
    "\n",
    "        # Parse the HTML into Beautiful Soup\n",
    "        soup = BeautifulSoup(page_html,'lxml')\n",
    "        \n",
    "        # Remove sections at end\n",
    "        bad_sections = ['See_also','Notes','References','Bibliography','External_links']\n",
    "        sections = soup.find_all('h2')\n",
    "        for section in sections:\n",
    "            if section.span['id'] in bad_sections:\n",
    "                \n",
    "                # Clean out the divs\n",
    "                div_siblings = section.find_next_siblings('div')\n",
    "                for sibling in div_siblings:\n",
    "                    sibling.clear()\n",
    "                    \n",
    "                # Clean out the ULs\n",
    "                ul_siblings = section.find_next_siblings('ul')\n",
    "                for sibling in ul_siblings:\n",
    "                    sibling.clear()\n",
    "        \n",
    "        # Delete tags associated with templates\n",
    "        for tag in soup.find_all('tr'):\n",
    "            tag.replace_with('')\n",
    "\n",
    "        # For each paragraph tag, extract the titles within the links\n",
    "        for para in soup.find_all('p'):\n",
    "            for link in para.find_all('a'):\n",
    "                if link.has_attr('title'):\n",
    "                    title = link['title']\n",
    "                    # Ignore links that aren't interesting or are redlinks\n",
    "                    if all(bad not in title for bad in bad_titles) and 'redlink' not in link['href']:\n",
    "                        outlinks_list.append(title)\n",
    "\n",
    "        # For each unordered list, extract the titles within the child links\n",
    "        for unordered_list in soup.find_all('ul'):\n",
    "            for item in unordered_list.find_all('li'):\n",
    "                for link in item.find_all('a'):\n",
    "                    if link.has_attr('title'):\n",
    "                        title = link['title']\n",
    "                        # Ignore links that aren't interesting or are redlinks\n",
    "                        if all(bad not in title for bad in bad_titles) and 'redlink' not in link['href']:\n",
    "                            outlinks_list.append(title)\n",
    "\n",
    "    return outlinks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_memberships(page_title,lang='en'):\n",
    "    \"\"\"The function accepts a page_title and returns a list of categories\n",
    "    the page is a member of\n",
    "    \n",
    "    category_title - a string of the page name\n",
    "    \n",
    "    Returns:\n",
    "    members - a list containing strings of the categories of which the page is a mamber\n",
    "    \n",
    "    \"\"\"\n",
    "    _S=\"https://{1}.wikipedia.org/w/api.php?action=query&prop=categories&titles={0}&clprop=timestamp&clshow=!hidden&cllimit=500&format=json&formatversion=2\".format(page_title,lang)\n",
    "    json_response = requests.get(_S).json()\n",
    "\n",
    "    categories = list()\n",
    "\n",
    "    if 'pages' in json_response['query']:\n",
    "        if 'categories' in json_response['query']['pages'][0]:\n",
    "            for category in json_response['query']['pages'][0]['categories']:\n",
    "                title = category['title']#.split(':')[1]\n",
    "                categories.append(title)\n",
    "                #timestamp = category['timestamp']\n",
    "                #categories.append({title:timestamp})\n",
    "            \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_subcategories(category_title,lang='en'):\n",
    "    \"\"\"The function accepts a category_title and returns a list of the category's sub-categories\n",
    "    \n",
    "    category_title - a string (including \"Category:\" prefix) of the category name\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "    \n",
    "    Returns:\n",
    "    members - a list containing strings of the sub-categories in the category\n",
    "    \n",
    "    \"\"\"\n",
    "    # Replace spaces with underscores\n",
    "    category_title = category_title.replace(' ','_')\n",
    "    \n",
    "    # Make sure \"Category:\" appears in the title\n",
    "    if 'Category:' not in category_title:\n",
    "        category_title = 'Category:' + category_title\n",
    "        \n",
    "    _S=\"https://{1}.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle={0}&cmtype=subcat&cmprop=title&cmlimit=500&format=json&formatversion=2\".format(category_title,lang)\n",
    "    json_response = requests.get(_S).json()\n",
    "\n",
    "    members = list()\n",
    "    \n",
    "    if 'categorymembers' in json_response['query']:\n",
    "        for member in json_response['query']['categorymembers']:\n",
    "            members.append(member['title'])\n",
    "            \n",
    "    return members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_members(category_title,depth=1,lang='en'):\n",
    "    \"\"\"The function accepts a category_title and returns a list of category members\n",
    "    \n",
    "    category_title - a string (including \"Category:\" prefix) of the category name\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "    \n",
    "    Returns:\n",
    "    members - a list containing strings of the page titles in the category\n",
    "    \n",
    "    \"\"\"\n",
    "    # Replace spaces with underscores\n",
    "    category_title = category_title.replace(' ','_')\n",
    "    \n",
    "    # Make sure \"Category:\" appears in the title\n",
    "    if 'Category:' not in category_title:\n",
    "        category_title = 'Category:' + category_title\n",
    "    \n",
    "    _S=\"https://{1}.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle={0}&cmprop=title&cmnamespace=0&cmlimit=500&format=json&formatversion=2\".format(category_title,lang)\n",
    "    json_response = requests.get(_S).json()\n",
    "\n",
    "    members = list()\n",
    "    \n",
    "    if depth < 0:\n",
    "        return members\n",
    "    \n",
    "    if 'categorymembers' in json_response['query']:\n",
    "        for member in json_response['query']['categorymembers']:\n",
    "            members.append(member['title'])\n",
    "            \n",
    "    subcats = get_category_subcategories(category_title,lang=lang)\n",
    "    \n",
    "    for subcat in subcats:\n",
    "        members += get_category_members(subcat,depth-1)\n",
    "            \n",
    "    return members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_external_links(page_title,lang='en'):\n",
    "    external_links = list()\n",
    "    \n",
    "    query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&titles={0}&prop=extlinks&ellimit=500&format=json&formatversion=2\".format(page_title,lang)\n",
    "    json_response = requests.get(query_string).json()\n",
    "    \n",
    "    if 'missing' not in json_response['query']['pages'][0] and 'extlinks' in json_response['query']['pages'][0]:\n",
    "        extlinks = json_response['query']['pages'][0]['extlinks']\n",
    "        \n",
    "        # Clean the extlinks\n",
    "        cleaned_extlinks = list()\n",
    "        \n",
    "        for l in extlinks:\n",
    "            if 'web.archive.org' in l['url']: # Internet Archives have two https in them, get the second\n",
    "                raw_url = 'http://' + l['url'].split('/http://')[1]\n",
    "            else:\n",
    "                raw_url = l['url']\n",
    "            \n",
    "            # Try to use the tldextract function, otherwise fall back to urlparse\n",
    "            try:\n",
    "                netloc = \"{0}.{1}\".format(tldextract.extract(raw_url).domain, tldextract.extract(raw_url).suffix)\n",
    "            except:\n",
    "                netloc = urlparse(raw_url).netloc\n",
    "                \n",
    "            external_links.append(netloc)\n",
    "    \n",
    "    return external_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redirects linking to a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_redirects_linking_here(page_title,lang='en',namespace=0):\n",
    "    \"\"\"Takes a page title and returns a list of redirects linking to the page\n",
    "    \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language \n",
    "        edition, defaults to \"en\"\n",
    "    namespace - limit to pages from a specific namespace, defaults to 0\n",
    "    \n",
    "    Returns:\n",
    "    linkshere - a list of strings with the redirect titles\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the response from the API for a query\n",
    "    # After passing a page title, the API returns the HTML markup of the current article version within a JSON payload\n",
    "    \n",
    "    lh_list = list()\n",
    "    \n",
    "    query_string = 'https://{1}.wikipedia.org/w/api.php?action=query&titles={0}&prop=linkshere&lhprop=title|redirect&lhnamespace={2}&lhshow=redirect&lhlimit=500&format=json&formatversion=2'.format(page_title,lang,namespace)\n",
    "    json_response = requests.get(query_string).json()\n",
    "    \n",
    "    if 'linkshere' in json_response['query']['pages'][0]:\n",
    "        subquery_lh_list = json_response['query']['pages'][0]['linkshere']\n",
    "        lh_list += subquery_lh_list\n",
    "    \n",
    "        while True:\n",
    "\n",
    "            if 'continue' not in json_response:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                query_continue = json_response['continue']['lhcontinue']\n",
    "                query_string = 'https://{1}.wikipedia.org/w/api.php?action=query&titles={0}&lhcontinue={3}&prop=linkshere&lhprop=title|redirect&lhnamespace={2}&lhshow=redirect&lhlimit=500&format=json&formatversion=2'.format(page_title,lang,namespace,query_continue)\n",
    "                json_response = requests.get(query_string).json()\n",
    "                subquery_lh_list = json_response['query']['pages'][0]['linkshere']\n",
    "                lh_list += subquery_lh_list\n",
    "    \n",
    "    return [i['title'] for i in lh_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_log_events(page_title,lang='en'):\n",
    "    \"\"\"Takes Wikipedia page title and returns a list of revisions\n",
    "    \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "        \n",
    "    Returns:\n",
    "    revision_list - a list of dictionaries, where each dictionary is the revision\n",
    "        meta-data susch as parentid, revid,sha1, size, timestamp, and user name\n",
    "    \"\"\"\n",
    "    \n",
    "    event_list = list()\n",
    "    \n",
    "    query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&letitle={0}&list=logevents&leprop=ids|title|type|user|userid|timestamp|comment|tags&lelimit=500&format=json&formatversion=2\".format(page_title,lang)\n",
    "    json_response = requests.get(query_string).json()\n",
    "\n",
    "    subquery_revision_list = json_response['query']['logevents']\n",
    "    event_list += subquery_revision_list\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        if 'continue' not in json_response:\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            query_continue = json_response['continue']['lecontinue']\n",
    "            query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&letitle={0}&list=logevents&leprop=ids|title|type|user|userid|timestamp|comment|tags&lelimit=500&lecontinue={2}&format=json&formatversion=2\".format(page_title,lang,query_continue)\n",
    "            json_response = requests.get(query_string).json()\n",
    "            subquery_revision_list = json_response['query']['logevents']\n",
    "            event_list += subquery_revision_list\n",
    "            #time.sleep(1)\n",
    "    \n",
    "    df = pd.DataFrame(event_list)\n",
    "    df['page'] = page_title\n",
    "    \n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df['date'] = df['timestamp'].apply(lambda x:x.date())\n",
    "    \n",
    "    if 'userid' in df.columns:\n",
    "        df['userid'] = df['userid'].fillna(0).apply(lambda x:str(int(x)))\n",
    "    #df['lang'] = lang\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pageviews(page_title,lang='en',date_from='20150701',date_to=str(datetime.today().date()).replace('-','')):\n",
    "    \"\"\"Takes Wikipedia page title and returns a all the various pageview records\n",
    "    \n",
    "    page_title - a string with the title of the page on Wikipedia\n",
    "    lang - a string (typically two letter ISO 639-1 code) for the language edition,\n",
    "        defaults to \"en\"\n",
    "        datefrom - a date string in a YYYYMMDD format, defaults to 20150701\n",
    "        dateto - a date string in a YYYYMMDD format, defaults to today\n",
    "        \n",
    "    Returns:\n",
    "    revision_list - a DataFrame indexed by date and multi-columned by agent and access type\n",
    "    \"\"\"\n",
    "    quoted_page_title = quote(page_title, safe='')\n",
    "    \n",
    "    df_list = []\n",
    "    for access in ['all-access','desktop','mobile-app','mobile-web']:\n",
    "        for agent in ['all-agents','user','spider','bot']:\n",
    "            s = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/{1}.wikipedia.org/{2}/{3}/{0}/daily/{4}/{5}\".format(quoted_page_title,lang,access,agent,date_from,date_to)\n",
    "            json_response = requests.get(s).json()\n",
    "            df = pd.DataFrame(json_response['items'])\n",
    "            df_list.append(df)\n",
    "\n",
    "    concat_df = pd.concat(df_list)\n",
    "    concat_df['timestamp'] = pd.to_datetime(concat_df['timestamp'],format='%Y%m%d%H')\n",
    "    concat_df = concat_df.set_index(['timestamp','agent','access'])['views'].unstack([1,2]).sort_index(axis=1)\n",
    "    concat_df[('page','page')] = page_title\n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>agent</th>\n",
       "      <th colspan=\"4\" halign=\"left\">all-agents</th>\n",
       "      <th colspan=\"4\" halign=\"left\">bot</th>\n",
       "      <th colspan=\"4\" halign=\"left\">spider</th>\n",
       "      <th colspan=\"4\" halign=\"left\">user</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>82159</td>\n",
       "      <td>35886</td>\n",
       "      <td>1292</td>\n",
       "      <td>44981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>81749</td>\n",
       "      <td>35496</td>\n",
       "      <td>1292</td>\n",
       "      <td>44961</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>83458</td>\n",
       "      <td>37554</td>\n",
       "      <td>1453</td>\n",
       "      <td>44451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>83055</td>\n",
       "      <td>37189</td>\n",
       "      <td>1453</td>\n",
       "      <td>44413</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>55615</td>\n",
       "      <td>22154</td>\n",
       "      <td>997</td>\n",
       "      <td>32464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>55174</td>\n",
       "      <td>21735</td>\n",
       "      <td>997</td>\n",
       "      <td>32442</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>43865</td>\n",
       "      <td>16640</td>\n",
       "      <td>795</td>\n",
       "      <td>26430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>43373</td>\n",
       "      <td>16171</td>\n",
       "      <td>795</td>\n",
       "      <td>26407</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>42220</td>\n",
       "      <td>16158</td>\n",
       "      <td>819</td>\n",
       "      <td>25243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>41914</td>\n",
       "      <td>15867</td>\n",
       "      <td>819</td>\n",
       "      <td>25228</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "agent      all-agents                                      bot          \\\n",
       "access     all-access desktop mobile-app mobile-web all-access desktop   \n",
       "timestamp                                                                \n",
       "2015-07-01      82159   35886       1292      44981          0       0   \n",
       "2015-07-02      83458   37554       1453      44451          0       0   \n",
       "2015-07-03      55615   22154        997      32464          0       0   \n",
       "2015-07-04      43865   16640        795      26430          0       0   \n",
       "2015-07-05      42220   16158        819      25243          0       0   \n",
       "\n",
       "agent                                spider                                \\\n",
       "access     mobile-app mobile-web all-access desktop mobile-app mobile-web   \n",
       "timestamp                                                                   \n",
       "2015-07-01          0          0        410     390          0         20   \n",
       "2015-07-02          0          0        403     365          0         38   \n",
       "2015-07-03          0          0        441     419          0         22   \n",
       "2015-07-04          0          0        492     469          0         23   \n",
       "2015-07-05          0          0        306     291          0         15   \n",
       "\n",
       "agent            user                                        page  \n",
       "access     all-access desktop mobile-app mobile-web          page  \n",
       "timestamp                                                          \n",
       "2015-07-01      81749   35496       1292      44961  Donald Trump  \n",
       "2015-07-02      83055   37189       1453      44413  Donald Trump  \n",
       "2015-07-03      55174   21735        997      32442  Donald Trump  \n",
       "2015-07-04      43373   16171        795      26407  Donald Trump  \n",
       "2015-07-05      41914   15867        819      25228  Donald Trump  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pv = get_pageviews('Donald Trump')\n",
    "_pv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the pages related to the Trump family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 949 members of the 'Trump Family' category on English Wikipedia\n"
     ]
    }
   ],
   "source": [
    "trump_category_members = get_category_members('Category:Trump_family',depth=5)\n",
    "print(\"There are {0:,} members of the 'Trump Family' category on English Wikipedia\".format(len(set(trump_category_members))))\n",
    "\n",
    "unique_trump_category_members = list(set(trump_category_members))\n",
    "\n",
    "with open('trump_category_members.json','w') as f:\n",
    "    json.dump(unique_trump_category_members,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,340 members of the 'Clinton Family' category on English Wikipedia\n"
     ]
    }
   ],
   "source": [
    "clinton_category_members = get_category_members('Category:Family_of_Bill_and_Hillary_Clinton',depth=5)\n",
    "print(\"There are {0:,} members of the 'Clinton Family' category on English Wikipedia\".format(len(set(clinton_category_members))))\n",
    "\n",
    "unique_clinton_category_members = list(set(clinton_category_members))\n",
    "\n",
    "with open('clinton_category_members.json','w') as f:\n",
    "    json.dump(unique_clinton_category_members,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisions\n",
    "Get the revisions for each of these pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('trump_category_members.json','r') as f:\n",
    "    unique_trump_category_members = json.load(f)\n",
    "    \n",
    "with open('clinton_category_members.json','r') as f:\n",
    "    unique_clinton_category_members = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on \"President Forever 2008 + Primaries\"\n",
      "Error on \"Robert \"Say\" McIntosh\"\n",
      "Error on \"South Park: Bigger, Longer & Uncut\"\n"
     ]
    }
   ],
   "source": [
    "error_pages = []\n",
    "\n",
    "for page in unique_trump_category_members:\n",
    "#for page in unique_clinton_category_members:\n",
    "    try:\n",
    "        _df = get_page_revisions(page)\n",
    "        renamed_page = page.replace(' ','_').replace('/','-').replace(':','_-').replace('?','')\n",
    "        #_df.to_csv(_dir+'Data/Clinton/Revisions/{0}.csv'.format(renamed_page),encoding='utf8',index=False)\n",
    "        _df.to_csv(_dir+'Data/Trump/Revisions/{0}.csv'.format(renamed_page),encoding='utf8',index=False)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(page))\n",
    "        error_pages.append(page)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_pages += [i for i in unique_trump_category_members if ':' in i]\n",
    "#error_pages += [i for i in unique_clinton_category_members if ':' in i]\n",
    "\n",
    "for page in error_pages:\n",
    "    _df = get_page_revisions(page)\n",
    "    renamed_page = page.replace(' ','_').replace('/','-').replace(':','_-').replace('?','')\n",
    "    _df.to_csv(_dir+'Data/Trump/Revisions/{0}.csv'.format(renamed_page),encoding='utf8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon</th>\n",
       "      <th>comment</th>\n",
       "      <th>commenthidden</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>parentid</th>\n",
       "      <th>revid</th>\n",
       "      <th>sha1</th>\n",
       "      <th>sha1hidden</th>\n",
       "      <th>size</th>\n",
       "      <th>suppressed</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>userhidden</th>\n",
       "      <th>userid</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>size_diff</th>\n",
       "      <th>prev_user</th>\n",
       "      <th>rev_index</th>\n",
       "      <th>age</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-05</td>\n",
       "      <td>104th United States Congress</td>\n",
       "      <td>0</td>\n",
       "      <td>2322487</td>\n",
       "      <td>5d453b39808f887cf05cbda0875b086891e57b45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-05 23:44:02</td>\n",
       "      <td>Seth Ilys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-07</td>\n",
       "      <td>104th United States Congress</td>\n",
       "      <td>2322487</td>\n",
       "      <td>2348088</td>\n",
       "      <td>7eabcf8391925ce3efbf44d39d00411ba3c505de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-07 01:07:11</td>\n",
       "      <td>Fabiform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Seth Ilys</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-09</td>\n",
       "      <td>104th United States Congress</td>\n",
       "      <td>2348088</td>\n",
       "      <td>2547608</td>\n",
       "      <td>7956424fe9b3195797bd3fd25234b37392e25009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-09 20:33:48</td>\n",
       "      <td>Rmhermen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>421.0</td>\n",
       "      <td>Fabiform</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>242797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-27</td>\n",
       "      <td>104th United States Congress</td>\n",
       "      <td>2547608</td>\n",
       "      <td>2915574</td>\n",
       "      <td>9c192346c871dc8882e6866290662300d2f484cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-02-27 08:50:35</td>\n",
       "      <td>Vardion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Rmhermen</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1513007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-03-25</td>\n",
       "      <td>104th United States Congress</td>\n",
       "      <td>2915574</td>\n",
       "      <td>3475257</td>\n",
       "      <td>0cc6db379947ea9067c5433af6a08ea2f6db7c6d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-03-25 18:44:40</td>\n",
       "      <td>66.167.49.186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Vardion</td>\n",
       "      <td>4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2368445.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon comment commenthidden       date                          page  \\\n",
       "0  False     NaN           NaN 2004-02-05  104th United States Congress   \n",
       "1  False     NaN           NaN 2004-02-07  104th United States Congress   \n",
       "2  False     NaN           NaN 2004-02-09  104th United States Congress   \n",
       "3  False     NaN           NaN 2004-02-27  104th United States Congress   \n",
       "4   True     NaN           NaN 2004-03-25  104th United States Congress   \n",
       "\n",
       "   parentid    revid                                      sha1 sha1hidden  \\\n",
       "0         0  2322487  5d453b39808f887cf05cbda0875b086891e57b45        NaN   \n",
       "1   2322487  2348088  7eabcf8391925ce3efbf44d39d00411ba3c505de        NaN   \n",
       "2   2348088  2547608  7956424fe9b3195797bd3fd25234b37392e25009        NaN   \n",
       "3   2547608  2915574  9c192346c871dc8882e6866290662300d2f484cd        NaN   \n",
       "4   2915574  3475257  0cc6db379947ea9067c5433af6a08ea2f6db7c6d        NaN   \n",
       "\n",
       "    size suppressed           timestamp           user userhidden  userid  \\\n",
       "0  19002        NaN 2004-02-05 23:44:02      Seth Ilys        NaN       0   \n",
       "1  19030        NaN 2004-02-07 01:07:11       Fabiform        NaN       0   \n",
       "2  19451        NaN 2004-02-09 20:33:48       Rmhermen        NaN       0   \n",
       "3  19478        NaN 2004-02-27 08:50:35        Vardion        NaN       0   \n",
       "4  19485        NaN 2004-03-25 18:44:40  66.167.49.186        NaN       0   \n",
       "\n",
       "   year  month  size_diff  prev_user  rev_index   age    latency  \n",
       "0  2004      2        NaN        NaN          0   0.0        NaN  \n",
       "1  2004      2       28.0  Seth Ilys          1   1.0    91389.0  \n",
       "2  2004      2      421.0   Fabiform          2   4.0   242797.0  \n",
       "3  2004      2       27.0   Rmhermen          3  21.0  1513007.0  \n",
       "4  2004      3        7.0    Vardion          4  49.0  2368445.0  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton_revision_df_list = []\n",
    "clinton_revision_files = os.listdir(_dir+'Data/Clinton/Revisions/')\n",
    "\n",
    "for f in clinton_revision_files:\n",
    "    try:\n",
    "        df = pd.read_csv(_dir + 'Data/Clinton/Revisions/{0}'.format(f),engine='python',parse_dates=['timestamp','date'])\n",
    "        clinton_revision_df_list.append(df)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(f))\n",
    "        pass\n",
    "    \n",
    "all_clinton_revisions_df = pd.concat(clinton_revision_df_list)\n",
    "all_clinton_revisions_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "all_clinton_revisions_df['year'] = all_clinton_revisions_df['date'].apply(lambda x:x.year)\n",
    "all_clinton_revisions_df['month'] = all_clinton_revisions_df['date'].apply(lambda x:x.month)\n",
    "all_clinton_revisions_df['anon'].fillna(False,inplace=True)\n",
    "all_clinton_revisions_df.sort_values(['page','timestamp'],ascending=True,inplace=True)\n",
    "all_clinton_revisions_df.reset_index(inplace=True,drop=True)\n",
    "all_clinton_revisions_df['size_diff'] = all_clinton_revisions_df.groupby('page')['size'].diff()\n",
    "all_clinton_revisions_df['prev_user'] = all_clinton_revisions_df.groupby('page')['user'].shift()\n",
    "all_clinton_revisions_df['rev_index'] = all_clinton_revisions_df.groupby('page')['timestamp'].apply(lambda x:x.argsort())\n",
    "all_clinton_revisions_df['age'] = all_clinton_revisions_df.groupby('page')['timestamp'].apply(lambda x:round((x-x.min())/pd.Timedelta(1,'d'),0))\n",
    "all_clinton_revisions_df['latency'] = all_clinton_revisions_df.groupby('page')['timestamp'].diff().apply(lambda x:x/pd.Timedelta(1,'s'))\n",
    "\n",
    "#all_page_revisions_df.to_csv('all_trump_page_revisions.csv',encoding='utf8',index=False)\n",
    "all_clinton_revisions_df.to_csv('all_clinton_page_revisions.csv',encoding='utf8',index=False)\n",
    "\n",
    "all_clinton_revisions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon</th>\n",
       "      <th>comment</th>\n",
       "      <th>commenthidden</th>\n",
       "      <th>date</th>\n",
       "      <th>page</th>\n",
       "      <th>parentid</th>\n",
       "      <th>revid</th>\n",
       "      <th>sha1</th>\n",
       "      <th>sha1hidden</th>\n",
       "      <th>size</th>\n",
       "      <th>suppressed</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>userhidden</th>\n",
       "      <th>userid</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>size_diff</th>\n",
       "      <th>prev_user</th>\n",
       "      <th>rev_index</th>\n",
       "      <th>age</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>/r/The Donald</td>\n",
       "      <td>0</td>\n",
       "      <td>732214190</td>\n",
       "      <td>4e740bd73bb2774f20bd07e47c82aecef915d2db</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-30 11:42:31</td>\n",
       "      <td>Nyuszika7H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>/r/The Donald</td>\n",
       "      <td>732214190</td>\n",
       "      <td>732214592</td>\n",
       "      <td>2f0d2e463baf26803e343652b3f9bf5cfed3d552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-30 11:46:38</td>\n",
       "      <td>Nyuszika7H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Nyuszika7H</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-16</td>\n",
       "      <td>/r/The Donald</td>\n",
       "      <td>732214592</td>\n",
       "      <td>739695016</td>\n",
       "      <td>399fd716f6bea87cfe8d4378d8bca16f4fcfece3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-16 11:13:20</td>\n",
       "      <td>RussBot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Nyuszika7H</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4145202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-08</td>\n",
       "      <td>/r/The Donald</td>\n",
       "      <td>739695016</td>\n",
       "      <td>743240915</td>\n",
       "      <td>1aca16fca4e79cf715ce3970edebafaebec922a4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-08 18:38:31</td>\n",
       "      <td>Paine Ellsworth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>84.0</td>\n",
       "      <td>RussBot</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1927511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-24</td>\n",
       "      <td>/r/The Donald</td>\n",
       "      <td>743240915</td>\n",
       "      <td>751319407</td>\n",
       "      <td>b7e9a0ae82d2f2337c03c10adbebcee2e7b0c3f2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-24 21:31:53</td>\n",
       "      <td>Yoshiman6464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>5086.0</td>\n",
       "      <td>Paine Ellsworth</td>\n",
       "      <td>4</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4071202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon comment commenthidden       date           page   parentid  \\\n",
       "0  False     NaN           NaN 2016-07-30  /r/The Donald          0   \n",
       "1  False     NaN           NaN 2016-07-30  /r/The Donald  732214190   \n",
       "2  False     NaN           NaN 2016-09-16  /r/The Donald  732214592   \n",
       "3  False     NaN           NaN 2016-10-08  /r/The Donald  739695016   \n",
       "4  False     NaN           NaN 2016-11-24  /r/The Donald  743240915   \n",
       "\n",
       "       revid                                      sha1 sha1hidden  size  \\\n",
       "0  732214190  4e740bd73bb2774f20bd07e47c82aecef915d2db        NaN    42   \n",
       "1  732214592  2f0d2e463baf26803e343652b3f9bf5cfed3d552        NaN    87   \n",
       "2  739695016  399fd716f6bea87cfe8d4378d8bca16f4fcfece3        NaN   139   \n",
       "3  743240915  1aca16fca4e79cf715ce3970edebafaebec922a4        NaN   223   \n",
       "4  751319407  b7e9a0ae82d2f2337c03c10adbebcee2e7b0c3f2        NaN  5309   \n",
       "\n",
       "  suppressed           timestamp             user userhidden  userid  year  \\\n",
       "0        NaN 2016-07-30 11:42:31       Nyuszika7H        NaN       0  2016   \n",
       "1        NaN 2016-07-30 11:46:38       Nyuszika7H        NaN       0  2016   \n",
       "2        NaN 2016-09-16 11:13:20          RussBot        NaN       0  2016   \n",
       "3        NaN 2016-10-08 18:38:31  Paine Ellsworth        NaN       0  2016   \n",
       "4        NaN 2016-11-24 21:31:53     Yoshiman6464        NaN       0  2016   \n",
       "\n",
       "   month  size_diff        prev_user  rev_index    age    latency  \n",
       "0      7        NaN              NaN          0    0.0        NaN  \n",
       "1      7       45.0       Nyuszika7H          1    0.0      247.0  \n",
       "2      9       52.0       Nyuszika7H          2   48.0  4145202.0  \n",
       "3     10       84.0          RussBot          3   70.0  1927511.0  \n",
       "4     11     5086.0  Paine Ellsworth          4  117.0  4071202.0  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_revision_df_list = []\n",
    "trump_revision_files = os.listdir(_dir+'Data/Trump/Revisions/')\n",
    "\n",
    "for f in trump_revision_files:\n",
    "    try:\n",
    "        df = pd.read_csv(_dir + 'Data/Trump/Revisions/{0}'.format(f),engine='python',parse_dates=['timestamp','date'])\n",
    "        trump_revision_df_list.append(df)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(f))\n",
    "        pass\n",
    "    \n",
    "all_trump_revisions_df = pd.concat(trump_revision_df_list)\n",
    "all_trump_revisions_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "all_trump_revisions_df['year'] = all_trump_revisions_df['date'].apply(lambda x:x.year)\n",
    "all_trump_revisions_df['month'] = all_trump_revisions_df['date'].apply(lambda x:x.month)\n",
    "all_trump_revisions_df['anon'].fillna(False,inplace=True)\n",
    "all_trump_revisions_df.sort_values(['page','timestamp'],ascending=True,inplace=True)\n",
    "all_trump_revisions_df.reset_index(inplace=True,drop=True)\n",
    "all_trump_revisions_df['size_diff'] = all_trump_revisions_df.groupby('page')['size'].diff()\n",
    "all_trump_revisions_df['prev_user'] = all_trump_revisions_df.groupby('page')['user'].shift()\n",
    "all_trump_revisions_df['rev_index'] = all_trump_revisions_df.groupby('page')['timestamp'].apply(lambda x:x.argsort())\n",
    "all_trump_revisions_df['age'] = all_trump_revisions_df.groupby('page')['timestamp'].apply(lambda x:round((x-x.min())/pd.Timedelta(1,'d'),0))\n",
    "all_trump_revisions_df['latency'] = all_trump_revisions_df.groupby('page')['timestamp'].diff().apply(lambda x:x/pd.Timedelta(1,'s'))\n",
    "\n",
    "all_trump_revisions_df.to_csv('all_trump_page_revisions.csv',encoding='utf8',index=False)\n",
    "\n",
    "all_trump_revisions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,467 active Clinton users.\n",
      "There are 2,969 active Trump users\n",
      "There are 3,016 in both sets.\n"
     ]
    }
   ],
   "source": [
    "all_clinton_subdf = all_clinton_revisions_df[(~all_clinton_revisions_df['anon']) & (~all_clinton_revisions_df['user'].isin(bot_list)) & (all_clinton_revisions_df['timestamp'] >= pd.Timestamp('2015-01-01')) & (all_clinton_revisions_df['timestamp'] <= pd.Timestamp('2017-11-09'))]\n",
    "all_trump_subdf = all_trump_revisions_df[(~all_trump_revisions_df['anon']) & (~all_trump_revisions_df['user'].isin(bot_list))  & (all_trump_revisions_df['timestamp'] >= pd.Timestamp('2015-01-01')) & (all_trump_revisions_df['timestamp'] <= pd.Timestamp('2017-11-09'))]\n",
    "both_subdf = pd.concat([all_clinton_subdf,all_trump_subdf])\n",
    "\n",
    "all_clinton_articles = all_clinton_subdf['page'].unique()\n",
    "all_trump_articles = all_trump_revisions_df['page'].unique()\n",
    "\n",
    "#all_clinton_subdf_user_agg = all_clinton_subdf.groupby('user').agg({'sha1':pd.Series.nunique,'page':pd.Series.nunique,'timestamp':lambda x:(x.max() - x.min())/np.timedelta64(1,'D')})\n",
    "#all_trump_subdf_user_agg = all_trump_subdf.groupby('user').agg({'sha1':pd.Series.nunique,'page':pd.Series.nunique,'timestamp':lambda x:(x.max() - x.min())/np.timedelta64(1,'D')})\n",
    "both_subdf_user_agg = both_subdf.groupby('user').agg({'sha1':pd.Series.nunique,'page':pd.Series.nunique,'timestamp':lambda x:(x.max() - x.min())/np.timedelta64(1,'D')})\n",
    "\n",
    "sha1_threshold = 5\n",
    "page_threshold = 3\n",
    "time_threshold = 1\n",
    "#active_clinton_users_df = all_clinton_subdf_user_agg[(all_clinton_subdf_user_agg['sha1'] >= sha1_threshold) & (all_clinton_subdf_user_agg['page'] >= page_threshold) & (all_clinton_subdf_user_agg['timestamp'] >= time_threshold)]\n",
    "#active_trump_users_df = all_trump_subdf_user_agg[(all_trump_subdf_user_agg['sha1'] >= sha1_threshold) & (all_trump_subdf_user_agg['page'] >= page_threshold) & (all_trump_subdf_user_agg['timestamp'] >= time_threshold)]\n",
    "both_active_users_df = both_subdf_user_agg[(both_subdf_user_agg['sha1'] >= sha1_threshold) & (both_subdf_user_agg['page'] >= page_threshold) & (both_subdf_user_agg['timestamp'] >= time_threshold)]\n",
    "\n",
    "clinton_active_users = both_subdf[(both_subdf['page'].isin(all_clinton_articles)) & (both_subdf['user'].isin(both_active_users_df.index))]['user'].unique()\n",
    "trump_active_users = both_subdf[(both_subdf['page'].isin(all_trump_articles)) & (both_subdf['user'].isin(both_active_users_df.index))]['user'].unique()\n",
    "\n",
    "#print(\"There are {0:,} active Clinton users.\\nThere are {1:,} active Trump users\\nThere are {2:,} in both sets.\".format(len(active_clinton_users),len(active_trump_users),len(both_active_users_df)))\n",
    "print(\"There are {0:,} active Clinton users.\\nThere are {1:,} active Trump users\\nThere are {2:,} in both sets.\".format(len(clinton_active_users),len(trump_active_users),len(both_active_users_df)))\n",
    "\n",
    "with open('active_users_clinton.json','w') as f:\n",
    "    json.dump(list(clinton_active_users),f)\n",
    "    \n",
    "with open('active_users_trump.json','w') as f:\n",
    "    json.dump(list(trump_active_users),f)\n",
    "    \n",
    "with open('active_users_both.json','w') as f:\n",
    "    json.dump(list(both_active_users_df.index),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2420"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(clinton_active_users) & set(trump_active_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it from disk if you haven't done all the crawling from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('clinton_active_users.json','r') as f:\n",
    "#    active_clinton_users = json.load(f)\n",
    "    \n",
    "#with open('trump_active_users.json','r') as f:\n",
    "#    active_trump_users = json.load(f)\n",
    "\n",
    "with open('active_users_both.json','r') as f:\n",
    "    active_both_users = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top user information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#active_clinton_userinfo = get_user_info(active_clinton_users)\n",
    "#active_trump_userinfo = get_user_info(active_trump_users)\n",
    "\n",
    "active_both_userinfo = get_user_info(active_both_users)\n",
    "\n",
    "#with open('userinfo_active_users_clinton.json','w') as f:\n",
    "#    json.dump(active_clinton_users,f)\n",
    "#with open('userinfo_active_users_trump.json','w') as f:\n",
    "#    json.dump(active_trump_userinfo,f)\n",
    "\n",
    "with open('userinfo_active_users_both.json','w') as f:\n",
    "    json.dump(active_both_userinfo,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('userinfo_active_users_clinton.json','w') as f:\n",
    "#    json.dump(active_clinton_users,f)\n",
    "    \n",
    "#with open('userinfo_active_users_trump.json','w') as f:\n",
    "#    json.dump(active_trump_userinfo,f)\n",
    "\n",
    "with open('userinfo_active_users_both.json','w') as f:\n",
    "    json.dump(active_both_userinfo,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'blockedby': 'Someguy1221',\n",
       "  'blockedbyid': 3315180,\n",
       "  'blockedtimestamp': '2017-01-10T22:49:46Z',\n",
       "  'blockexpiry': 'infinity',\n",
       "  'blockid': 7125860,\n",
       "  'blockreason': '[[WP:3RR|3RR]] violation on [[/r/The Donald]]',\n",
       "  'editcount': 153,\n",
       "  'gender': 'unknown',\n",
       "  'groups': ['*', 'user', 'autoconfirmed'],\n",
       "  'name': 'Archer Rafferty',\n",
       "  'registration': '2016-08-10T12:14:24Z',\n",
       "  'userid': 28931392}]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in active_both_userinfo if i['name'] == \"Archer Rafferty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = \"Archer Rafferty\"\n",
    "lang = \"en\"\n",
    "start,stop = pd.Timestamp('2013-01-01'), pd.Timestamp('2017-11-09')\n",
    "start_utc = datetime.strftime(start, '%Y-%m-%dT%H:%M:%SZ')\n",
    "stop_utc = datetime.strftime(stop, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&list=usercontribs&ucuser={0}&ucprop=ids|title|comment|timestamp|flags|size|sizediff&ucstart={2}&ucstop={3}&uclimit=500&ucdir=newer&format=json&formatversion=2\".format(username,lang,start_utc,stop_utc)\n",
    "json_response = requests.get(query_string).json()\n",
    "subquery_revision_list = json_response['query']['usercontribs']\n",
    "    \n",
    "revision_list = list()\n",
    "\n",
    "# If the first 500 edits took place in less than 30 days, we've got ourselves a power user, bot, or cyborg\n",
    "earliest_first_500 = pd.to_datetime(json_response['query']['usercontribs'][0]['timestamp'])\n",
    "latest_first_500 = pd.to_datetime(json_response['query']['usercontribs'][-1]['timestamp'])\n",
    "days_elapsed_first_500 = latest_first_500 - earliest_first_500\n",
    "\n",
    "if len(subquery_revision_list) == 500 and days_elapsed_first_500 > np.timedelta64(30,'D'):\n",
    "\n",
    "    revision_list += subquery_revision_list\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if 'continue' not in json_response:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            query_continue = json_response['continue']['uccontinue']\n",
    "            query_string = \"https://{1}.wikipedia.org/w/api.php?action=query&list=usercontribs&ucuser={0}&ucprop=ids|title|comment|timestamp|flags|size|sizediff&ucstart={2}&ucstop={3}&uclimit=500&ucdir=newer&uccontinue={4}&format=json&formatversion=2\".format(username,lang,start_utc,stop_utc,query_continue)\n",
    "            json_response = requests.get(query_string).json()\n",
    "            subquery_revision_list = json_response['query']['usercontribs']\n",
    "            revision_list += subquery_revision_list\n",
    "            #time.sleep(1)\n",
    "\n",
    "elif 'continue' not in json_response:\n",
    "\n",
    "    revision_list += subquery_revision_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top user contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At position: 0\n",
      "Error on \"Arms\"\n",
      "Error on \"Arxiloxos\"\n",
      "Error on \"Asdasdasdff\"\n",
      "Error on \"Ashvio\"\n",
      "Error on \"Aspects\"\n",
      "Error on \"AusLondonder\"\n",
      "Error on \"AussieLegend\"\n",
      "Error on \"AustralianRupert\"\n",
      "Error on \"Averageguy007\"\n",
      "Error on \"Azwu\"\n",
      "Error on \"BD2412\"\n",
      "Error on \"BDD\"\n",
      "Error on \"BURSTHON3\"\n",
      "Error on \"BabbaQ\"\n",
      "Error on \"Backendgaming\"\n",
      "Error on \"BaldBoris\"\n",
      "Error on \"Barek\"\n",
      "Error on \"BattlegroundsGames\"\n",
      "Error on \"Bbb23\"\n",
      "Error on \"Beaglemix\"\n",
      "Error on \"Bearcat\"\n",
      "Error on \"Bender the Bot\"\n",
      "Error on \"Bender235\"\n",
      "Error on \"Bennettn1997\"\n",
      "Error on \"Benshim333\"\n",
      "Error on \"BethNaught\"\n",
      "Error on \"Beyond My Ken\"\n",
      "Error on \"Bgwhite\"\n",
      "Error on \"Bigmdude1\"\n",
      "Error on \"BilCat\"\n",
      "Error on \"Billy Hathorn\"\n",
      "Error on \"Binksternet\"\n",
      "Error on \"Biosthmors\"\n",
      "Error on \"BizarreLoveTriangle\"\n",
      "Error on \"Bjhillis\"\n",
      "Error on \"Bkonrad\"\n",
      "Error on \"BlackGhost2280\"\n",
      "Error on \"BlackTerror\"\n",
      "Error on \"BlazeKing252\"\n",
      "Error on \"Blazoaustin\"\n",
      "Error on \"Blb226\"\n",
      "Error on \"BlobBlob98\"\n",
      "Error on \"Bluehotel\"\n",
      "Error on \"Bmclaughlin9\"\n",
      "Error on \"Bobby232332\"\n",
      "Error on \"Bobrayner\"\n",
      "Error on \"Bomberswarm2\"\n",
      "Error on \"Bongey\"\n",
      "Error on \"Bongwarrior\"\n",
      "Error on \"BoredBored\"\n",
      "Error on \"Brainboy109\"\n",
      "Error on \"BrandonT0421\"\n",
      "Error on \"Bridgetfox\"\n",
      "Error on \"BrokenSegue\"\n",
      "Error on \"BrownHairedGirl\"\n",
      "Error on \"Burger2227\"\n",
      "Error on \"Buster7\"\n",
      "Error on \"CAPTAIN RAJU\"\n",
      "Error on \"CAWylie\"\n",
      "Error on \"CLCStudent\"\n",
      "Error on \"CalSGWorker\"\n",
      "Error on \"Callanecc\"\n",
      "Error on \"Canadianfixerupper\"\n",
      "Error on \"Cardifform\"\n",
      "Error on \"Cariboukid\"\n",
      "Error on \"Carlos Danger\"\n",
      "Error on \"Catrope\"\n",
      "Error on \"Caviar Cohort\"\n",
      "Error on \"Certified Gangsta\"\n",
      "Error on \"Cgersten\"\n",
      "Error on \"Charles Essie\"\n",
      "Error on \"Chexandy89\"\n",
      "Error on \"Chris the speller\"\n",
      "Error on \"Chromium0818\"\n",
      "Error on \"Chrononem\"\n",
      "Error on \"Circusposters\"\n",
      "Error on \"CitationKneaded\"\n",
      "Error on \"CityOfSilver\"\n",
      "Error on \"Cjw1\"\n",
      "Error on \"Clarityfiend\"\n",
      "Error on \"Classafelonymonkey\"\n",
      "Error on \"ClassicOnAStick\"\n",
      "Error on \"Claomh Solais\"\n",
      "Error on \"Clemens Stockner\"\n",
      "Error on \"Cliffmore\"\n",
      "Error on \"Coffee\"\n",
      "Error on \"CoffeeStation95\"\n",
      "Error on \"CogitoErgoSum14\"\n",
      "Error on \"ColRad85\"\n",
      "Error on \"Colonel Wilhelm Klink\"\n",
      "Error on \"Colonies Chris\"\n",
      "Error on \"Comatmebro\"\n",
      "Error on \"CometEncke\"\n",
      "Error on \"Common Yarrow\"\n",
      "Error on \"CommonsDelinker\"\n",
      "Error on \"Compassionate727\"\n",
      "Error on \"Computermichael\"\n",
      "Error on \"Concrete Cloverleaf\"\n",
      "Error on \"Connormah\"\n",
      "Error on \"Continentaleurope\"\n",
      "Error on \"Coolyog\"\n",
      "Error on \"CopperWhopper67\"\n",
      "Error on \"Costatitanica\"\n",
      "Error on \"Courcelles\"\n",
      "Error on \"Cowik\"\n",
      "Error on \"Cowtown96\"\n",
      "Error on \"CraigFoyeRules\"\n",
      "Error on \"Craigrottman\"\n",
      "Error on \"CubeSat4U\"\n",
      "Error on \"Curly Turkey\"\n",
      "Error on \"Cwmhiraeth\"\n",
      "Error on \"Cybermann\"\n",
      "Error on \"Cyberpower678\"\n",
      "Error on \"Cydebot\"\n",
      "Error on \"Cynulliad3\"\n",
      "Error on \"Cyve\"\n",
      "Error on \"DGG\"\n",
      "Error on \"DMGUSA\"\n",
      "Error on \"DRAGON BOOSTER\"\n",
      "Error on \"DSmurf\"\n",
      "Error on \"Daaxix\"\n",
      "Error on \"DadaNeem\"\n",
      "Error on \"DagosNavy\"\n",
      "Error on \"Dakleman\"\n",
      "Error on \"Danhens\"\n",
      "Error on \"Daniel Case\"\n",
      "Error on \"Daniel Mietchen\"\n",
      "Error on \"DarkApollo\"\n",
      "Error on \"Dash77\"\n",
      "Error on \"Davey2116\"\n",
      "Error on \"David Eppstein\"\n",
      "Error on \"David in DC\"\n",
      "Error on \"Davidmejoradas\"\n",
      "Error on \"Dawn Bard\"\n",
      "Error on \"Dawnseeker2000\"\n",
      "Error on \"Dawynn\"\n",
      "Error on \"Dbachmann\"\n",
      "Error on \"Dcirovic\"\n",
      "Error on \"Dcpoliticaljunkie\"\n",
      "Error on \"Delaywaves\"\n",
      "Error on \"Deor\"\n",
      "Error on \"Devilfan30\"\n",
      "Error on \"Dewritech\"\n",
      "Error on \"Diannaa\"\n",
      "Error on \"Dicklyon\"\n",
      "Error on \"Dillon251992\"\n",
      "Error on \"Dimadick\"\n",
      "Error on \"Discospinster\"\n",
      "Error on \"Djflem\"\n",
      "Error on \"Dkspartan1835\"\n",
      "Error on \"Dlohcierekim\"\n",
      "Error on \"Dlodir95\"\n",
      "Error on \"Doblecaa\"\n",
      "Error on \"Doc James\"\n",
      "Error on \"DocWatson42\"\n",
      "Error on \"Dolly Cao\"\n",
      "Error on \"Don1182\"\n",
      "Error on \"Donenne\"\n",
      "Error on \"Doniago\"\n",
      "Error on \"Donovan O'Cooley\"\n",
      "Error on \"DoomLexus\"\n",
      "Error on \"Doug Weller\"\n",
      "Error on \"Dough4872\"\n",
      "Error on \"Dr.K.\"\n",
      "Error on \"DrCruse\"\n",
      "Error on \"DrKay\"\n",
      "Error on \"DrStrauss\"\n",
      "Error on \"Drbogdan\"\n",
      "Error on \"Drmies\"\n",
      "Error on \"Dsprc\"\n",
      "Error on \"Dthomsen8\"\n",
      "Error on \"Eamonster\"\n",
      "Error on \"Eclipsoid\"\n",
      "Error on \"EdJohnston\"\n",
      "Error on \"EdgarCabreraFaria\"\n",
      "Error on \"Edit semi-protected\"\n",
      "Error on \"EditDude\"\n",
      "Error on \"Editor2020\"\n",
      "At position: 600\n",
      "Error on \"Editr\"\n",
      "Error on \"Edmodo23\"\n",
      "Error on \"Edward\"\n",
      "Error on \"Eegcm\"\n",
      "Error on \"Egeymi\"\n",
      "Error on \"EkoGraf\"\n",
      "Error on \"Elinruby\"\n",
      "Error on \"Eloquence\"\n",
      "Error on \"Emigdioofmiami\"\n",
      "Error on \"Emily Goldstein\"\n",
      "Error on \"Emir of Wikipedia\"\n",
      "Error on \"Emmy Expert\"\n",
      "Error on \"Engineeringisawesome\"\n",
      "Error on \"English06\"\n",
      "Error on \"Epark360\"\n",
      "Error on \"Epeefleche\"\n",
      "Error on \"Equality 7-2522\"\n",
      "Error on \"Eric-Wester\"\n",
      "Error on \"EricEnfermero\"\n",
      "Error on \"EthanPender\"\n",
      "Error on \"EtienneDolet\"\n",
      "Error on \"EupDale\"\n",
      "Error on \"Evanh2008\"\n",
      "Error on \"Evenewyear\"\n",
      "Error on \"Ew34kl09df55\"\n",
      "Error on \"Excirial\"\n",
      "Error on \"FabulousFerd\"\n",
      "Error on \"Fadesga\"\n",
      "Error on \"FallingGravity\"\n",
      "Error on \"Favonian\"\n",
      "Error on \"Feminist\"\n",
      "Error on \"First Lord of Downing Street\"\n",
      "Error on \"Floates\"\n",
      "Error on \"Floridarmy\"\n",
      "Error on \"Flyer22 Reborn\"\n",
      "Error on \"Fmm134\"\n",
      "Error on \"Foghe\"\n",
      "Error on \"Fortdj33\"\n",
      "Error on \"Fortuna Imperatrix Mundi\"\n",
      "Error on \"Fouett rond de jambe en tournant\"\n",
      "Error on \"Franck Drake\"\n",
      "Error on \"Frankam12\"\n",
      "Error on \"Franzboas\"\n",
      "Error on \"Franois Robere\"\n",
      "Error on \"Frietjes\"\n",
      "Error on \"Froid\"\n",
      "Error on \"Furrymurry666\"\n",
      "Error on \"Fylbecatulous\"\n",
      "Error on \"GSS-1987\"\n",
      "Error on \"GTVM92\"\n",
      "Error on \"Gaas99\"\n",
      "Error on \"Gadget850\"\n",
      "Error on \"Gareth Griffith-Jones\"\n",
      "Error on \"Gbawden\"\n",
      "Error on \"Gene93k\"\n",
      "Error on \"George Ho\"\n",
      "Error on \"Geraldo Perez\"\n",
      "Error on \"Gerda Arendt\"\n",
      "Error on \"Ghert501\"\n",
      "Error on \"GhostOfNoMeme\"\n",
      "Error on \"Ghostmen2\"\n",
      "Error on \"Gik\"\n",
      "Error on \"Gilliam\"\n",
      "Error on \"Glacier2009\"\n",
      "Error on \"Gobonobo\"\n",
      "Error on \"Gogo Dodo\"\n",
      "Error on \"GoingBatty\"\n",
      "Error on \"GoldRingChip\"\n",
      "Error on \"Good Olfactory\"\n",
      "Error on \"GoodDay\"\n",
      "Error on \"Gorillaswar\"\n",
      "Error on \"Governor Jerchel\"\n",
      "Error on \"Graham87\"\n",
      "Error on \"GrahamHardy\"\n",
      "Error on \"Grammarxxx\"\n",
      "Error on \"GreenIn2010\"\n",
      "Error on \"GregorB\"\n",
      "Error on \"Grko3\"\n",
      "Error on \"Ground Zero\"\n",
      "Error on \"Grbergs Gra Sng\"\n",
      "Error on \"Guy Macon\"\n",
      "Error on \"Guy1890\"\n",
      "Error on \"GnniX\"\n",
      "Error on \"H McCringleberry\"\n",
      "Error on \"H.dryad\"\n",
      "Error on \"Haailo\"\n",
      "At position: 900\n",
      "Error on \"Hammersoft\"\n",
      "Error on \"HangingCurve\"\n",
      "Error on \"Happysailor\"\n",
      "Error on \"Hebrides\"\n",
      "Error on \"HenryMP02\"\n",
      "Error on \"Herblouise945\"\n",
      "Error on \"Hergilei\"\n",
      "Error on \"Hgb asicwizard\"\n",
      "Error on \"Hijiri88\"\n",
      "Error on \"Historybuff5182\"\n",
      "Error on \"Hmains\"\n",
      "Error on \"Hmlarson\"\n",
      "Error on \"Hmokjg\"\n",
      "Error on \"Hnic52\"\n",
      "Error on \"Home Lander\"\n",
      "Error on \"Hugo999\"\n",
      "Error on \"Huntermmoore11701\"\n",
      "Error on \"Huon\"\n",
      "Error on \"Hybridace101\"\n",
      "Error on \"I'm on day 4\"\n",
      "Error on \"IBestEditor\"\n",
      "Error on \"ICat Master\"\n",
      "Error on \"IP75\"\n",
      "Error on \"Iadmc\"\n",
      "Error on \"Iamthecheese44\"\n",
      "Error on \"Ian Page\"\n",
      "Error on \"Ianblair23\"\n",
      "Error on \"IceFrappe\"\n",
      "Error on \"IgnorantArmies\"\n",
      "Error on \"Ihardlythinkso\"\n",
      "Error on \"Im5yrsold\"\n",
      "Error on \"Immortal Horrors or Everlasting Splendors\"\n",
      "Error on \"Imzadi1979\"\n",
      "Error on \"In ictu oculi\"\n",
      "Error on \"Inspector Semenych\"\n",
      "Error on \"IntelligentName\"\n",
      "Error on \"JJMC89\"\n",
      "Error on \"Jack Frost\"\n",
      "Error on \"Jacklbell\"\n",
      "Error on \"JackofOz\"\n",
      "Error on \"Jakobees\"\n",
      "Error on \"Janweh64\"\n",
      "Error on \"Jarble\"\n",
      "Error on \"Jarodbuchta\"\n",
      "Error on \"Jatkins\"\n",
      "Error on \"Jauerback\"\n",
      "Error on \"Jax 0677\"\n",
      "Error on \"Jayron32\"\n",
      "Error on \"Jbfair728\"\n",
      "Error on \"Jbiestek4041\"\n",
      "Error on \"Jenks24\"\n",
      "Error on \"Jessicapierce\"\n",
      "Error on \"Jevansen\"\n",
      "Error on \"Jfhutson\"\n",
      "Error on \"Jimjianghk\"\n",
      "Error on \"Jj98\"\n",
      "Error on \"Jkerrigan9\"\n",
      "Error on \"Joalkap\"\n",
      "Error on \"JocularJellyfish\"\n",
      "Error on \"Joe Decker\"\n",
      "Error on \"JoeM\"\n",
      "Error on \"Joel62097\"\n",
      "Error on \"John\"\n",
      "Error on \"John Cline\"\n",
      "Error on \"John D. Rockerduck\"\n",
      "Error on \"John of Reading\"\n",
      "Error on \"Johnny3887\"\n",
      "Error on \"Johno95\"\n",
      "Error on \"Johnpacklambert\"\n",
      "Error on \"Jonah161\"\n",
      "Error on \"Joreberg\"\n",
      "Error on \"Joseph A. Spadaro\"\n",
      "Error on \"JoshuaKGarner\"\n",
      "Error on \"Joshualeverburg1\"\n",
      "Error on \"Jun Nijo\"\n",
      "Error on \"Justanothereditor98027\"\n",
      "Error on \"Justeditingtoday\"\n",
      "Error on \"Jw88p\"\n",
      "Error on \"Jweiss11\"\n",
      "Error on \"KAL68\"\n",
      "Error on \"KAP03\"\n",
      "At position: 1200\n",
      "Error on \"KConWiki\"\n",
      "Error on \"KINGOFTO\"\n",
      "Error on \"KMilos\"\n",
      "Error on \"Kamel Tebaast\"\n",
      "Error on \"KarlFrei\"\n",
      "Error on \"Keith D\"\n",
      "Error on \"Keithbob\"\n",
      "Error on \"Keithlouis2000\"\n",
      "Error on \"Kellymoat\"\n",
      "Error on \"Ken Gallager\"\n",
      "Error on \"Kerimb123\"\n",
      "Error on \"Kiernanmc\"\n",
      "Error on \"Kim9teen\"\n",
      "Error on \"Klarky15\"\n",
      "Error on \"Knife-in-the-drawer\"\n",
      "Error on \"Knowledgekid87\"\n",
      "Error on \"Koala15\"\n",
      "Error on \"Koavf\"\n",
      "Error on \"KolbertBot\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on \"Kookster66\"\n",
      "Error on \"Ksenia2006\"\n",
      "Error on \"Ksenia2727\"\n",
      "Error on \"Kuioooooo\"\n",
      "Error on \"KyleSolo2\"\n",
      "Error on \"KylieTastic\"\n",
      "Error on \"LDMaster1998\"\n",
      "Error on \"La-Li-Lu-Le-Lo\"\n",
      "Error on \"LacrimosaDiesIlla\"\n",
      "Error on \"LadyofShalott\"\n",
      "Error on \"Lance386\"\n",
      "Error on \"Landingdude13\"\n",
      "Error on \"LaughingNx\"\n",
      "Error on \"Lectonar\"\n",
      "Error on \"LeeBobBlack\"\n",
      "Error on \"Leof616\"\n",
      "Error on \"Lepricavark\"\n",
      "Error on \"Lighthouse3050\"\n",
      "Error on \"Lihaas\"\n",
      "Error on \"LikkerdySplit\"\n",
      "Error on \"Lilahdog568\"\n",
      "Error on \"LittleWink\"\n",
      "Error on \"Liz\"\n",
      "Error on \"Localemediamonitor\"\n",
      "Error on \"Lockley\"\n",
      "Error on \"Look2See1\"\n",
      "Error on \"Lotje\"\n",
      "Error on \"Lourdes\"\n",
      "Error on \"Luckiest0522\"\n",
      "Error on \"Luckycat092710\"\n",
      "Error on \"Ludwig van Mozart\"\n",
      "Error on \"Lugnuts\"\n",
      "Error on \"LukeStuartStar\"\n",
      "Error on \"Lumbering in thought\"\n",
      "Error on \"MX\"\n",
      "Error on \"MZMcBride\"\n",
      "Error on \"Machucanator1000\"\n",
      "Error on \"Magic links bot\"\n",
      "Error on \"Magicpotato123\"\n",
      "Error on \"Magioladitis\"\n",
      "Error on \"Majora\"\n",
      "Error on \"Make America Great Again\"\n",
      "Error on \"Malcolmxl5\"\n",
      "Error on \"Malik Shabazz\"\n",
      "Error on \"Mandarax\"\n",
      "Error on \"Mandate41\"\n",
      "Error on \"Manxruler\"\n",
      "Error on \"Mar4d\"\n",
      "Error on \"Marek69\"\n",
      "Error on \"Marianna251\"\n",
      "Error on \"Marine678\"\n",
      "Error on \"Mark Miller\"\n",
      "Error on \"Mark3210\"\n",
      "Error on \"Martinevans123\"\n",
      "Error on \"Masageee33\"\n",
      "Error on \"Masem\"\n",
      "Error on \"Maslowsneeds\"\n",
      "Error on \"Masschaos777\"\n",
      "Error on \"Masterknighted\"\n",
      "Error on \"Materialscientist\"\n",
      "Error on \"Matt714\"\n",
      "Error on \"Mattsam\"\n",
      "Error on \"Mawlidman\"\n",
      "Error on \"MaxMinkin\"\n",
      "Error on \"McGeddon\"\n",
      "Error on \"Mean as custard\"\n",
      "Error on \"Meatsgains\"\n",
      "Error on \"Medeis\"\n",
      "Error on \"MelanieN alt\"\n",
      "Error on \"MelbourneStar\"\n",
      "Error on \"Melinalosangeles\"\n",
      "Error on \"Memorykey12\"\n",
      "Error on \"Mercurywoodrose\"\n",
      "Error on \"Michael Bednarek\"\n",
      "Error on \"Midnightblueowl\"\n",
      "Error on \"Mike Rosoft\"\n",
      "Error on \"Mikey3778\"\n",
      "Error on \"MilborneOne\"\n",
      "Error on \"Mild Bill Hiccup\"\n",
      "Error on \"Milowent\"\n",
      "Error on \"Ministre d'tat\"\n",
      "Error on \"MissPiggysBoyfriend\"\n",
      "Error on \"Missvain\"\n",
      "Error on \"Misternails\"\n",
      "Error on \"Mkdw\"\n",
      "Error on \"Mnw2000\"\n",
      "Error on \"Moe Epsilon\"\n",
      "Error on \"Mojo Hand\"\n",
      "Error on \"Moonraker\"\n",
      "Error on \"Motivao\"\n",
      "Error on \"Moxy\"\n",
      "Error on \"Mr Stephen\"\n",
      "Error on \"MrSweeper\"\n",
      "Error on \"MrX\"\n",
      "Error on \"Mrmattdavis890\"\n",
      "Error on \"Mrothman98\"\n",
      "Error on \"Muboshgu\"\n",
      "Error on \"MurielMary\"\n",
      "Error on \"Musdan77\"\n",
      "Error on \"Mythlike-Cell\"\n",
      "Error on \"Mz7\"\n",
      "Error on \"Mlencron\"\n",
      "Error on \"Narbit\"\n",
      "Error on \"Nations United\"\n",
      "Error on \"NaturalSelection\"\n",
      "Error on \"Nbudion\"\n",
      "Error on \"Nemixis\"\n",
      "Error on \"Nerrawllehctim\"\n",
      "Error on \"Neuwert\"\n",
      "Error on \"Neve-selbert\"\n",
      "Error on \"Nhnewsguy789\"\n",
      "Error on \"Nicholas S8\"\n",
      "Error on \"Nick Number\"\n",
      "Error on \"Nick-D\"\n",
      "Error on \"Nick.aus96\"\n",
      "Error on \"Nick.mon\"\n",
      "Error on \"Nick845\"\n",
      "Error on \"Nicole.Paull\"\n",
      "Error on \"Nightscream\"\n",
      "Error on \"Nikkimaria\"\n",
      "Error on \"Nkrosse\"\n",
      "Error on \"No Swan So Fine\"\n",
      "Error on \"NoMoreHeroes\"\n",
      "Error on \"Non-dropframe\"\n",
      "Error on \"Nono1995\"\n",
      "Error on \"Norden1990\"\n",
      "Error on \"NorthBySouthBaranof\"\n",
      "Error on \"Northamerica1000\"\n",
      "Error on \"Notque\"\n",
      "Error on \"Nthep\"\n",
      "Error on \"Number 57\"\n",
      "Error on \"Nyttend\"\n",
      "Error on \"Nkkenbuer\"\n",
      "Error on \"OMEGAUNIT\"\n",
      "Error on \"Oathed\"\n",
      "Error on \"Obamapinoy1982\"\n",
      "Error on \"Oddishskies\"\n",
      "Error on \"Ohconfucius\"\n",
      "Error on \"Omni Flames\"\n",
      "Error on \"Omnipaedista\"\n",
      "Error on \"OnionRing\"\n",
      "Error on \"Optakeover\"\n",
      "Error on \"Orange U-turn\"\n",
      "Error on \"OrganicEarth\"\n",
      "Error on \"Oriole7\"\n",
      "Error on \"Oripaypaykim\"\n",
      "Error on \"Ost316\"\n",
      "Error on \"Overdraftfee\"\n",
      "Error on \"Oversteek\"\n",
      "At position: 1800\n",
      "Error on \"PKT\"\n",
      "Error on \"Paffylikescake\"\n",
      "Error on \"Paine Ellsworth\"\n",
      "Error on \"PamD\"\n",
      "Error on \"Pandroid\"\n",
      "Error on \"Pantextual\"\n",
      "Error on \"Parabolist\"\n",
      "Error on \"Paraney\"\n",
      "Error on \"Parkwells\"\n",
      "Error on \"Password123\"\n",
      "Error on \"PatrickShearing\"\n",
      "Error on \"Paul Keller\"\n",
      "Error on \"PerfectlyIrrational\"\n",
      "Error on \"Person 2203\"\n",
      "Error on \"PeteWL\"\n",
      "Error on \"Peter SamFan\"\n",
      "Error on \"Philip Cross\"\n",
      "Error on \"Phoenixfire213\"\n",
      "Error on \"Pigsonthewing\"\n",
      "Error on \"Pillsberrydoo7\"\n",
      "Error on \"Pinkleader\"\n",
      "Error on \"Pinnygold\"\n",
      "Error on \"Plastikspork\"\n",
      "Error on \"Pol098\"\n",
      "Error on \"Politicaleditordean\"\n",
      "Error on \"Ponyo\"\n",
      "Error on \"Ppt1973\"\n",
      "Error on \"Presidentman\"\n",
      "Error on \"PrimeBOT\"\n",
      "Error on \"ProprioMe OW\"\n",
      "Error on \"Pvmoutside\"\n",
      "Error on \"QianCheng\"\n",
      "Error on \"Quark1005\"\n",
      "Error on \"Quebec99\"\n",
      "Error on \"Quorum816\"\n",
      "Error on \"Qzd\"\n",
      "Error on \"R'n'B\"\n",
      "Error on \"R3venans\"\n",
      "Error on \"RFD\"\n",
      "Error on \"RJFJR\"\n",
      "Error on \"RachaelAMS\"\n",
      "Error on \"Racklever\"\n",
      "Error on \"RainFall\"\n",
      "Error on \"Rainyseattle\"\n",
      "Error on \"Ralphw\"\n",
      "Error on \"Ramaksoud2000\"\n",
      "Error on \"Random character sequence\"\n",
      "Error on \"Ravenclaw0127\"\n",
      "Error on \"RaymondCHedges\"\n",
      "Error on \"Redrose64\"\n",
      "Error on \"Reordcraeft\"\n",
      "Error on \"ResearchAmerica\"\n",
      "Error on \"RevelationDirect\"\n",
      "Error on \"Reverse polish\"\n",
      "Error on \"Rhydic\"\n",
      "Error on \"Rich Farmbrough\"\n",
      "Error on \"RightCowLeftCoast\"\n",
      "Error on \"Ritchie333\"\n",
      "Error on \"Rjensen\"\n",
      "Error on \"Rjwilmsi\"\n",
      "Error on \"Rlendog\"\n",
      "Error on \"Rms125a@hotmail.com\"\n",
      "Error on \"Robert McClenon\"\n",
      "Error on \"Robinette Q\"\n",
      "Error on \"Robofish\"\n",
      "Error on \"Robot psychiatrist\"\n",
      "Error on \"Rochester3000\"\n",
      "Error on \"Ronz\"\n",
      "Error on \"Rosiestep\"\n",
      "Error on \"Ross.smith\"\n",
      "Error on \"Rothorpe\"\n",
      "Error on \"RoundSquare\"\n",
      "Error on \"Rovv123\"\n",
      "Error on \"Rudolph Davis\"\n",
      "At position: 2100\n",
      "Error on \"SW3 5DL\"\n",
      "Error on \"Sactacoman\"\n",
      "Error on \"Saiph121\"\n",
      "Error on \"Sam Sailor\"\n",
      "Error on \"Samhiuy\"\n",
      "Error on \"Sanya3\"\n",
      "Error on \"SarekOfVulcan\"\n",
      "Error on \"Satellizer\"\n",
      "Error on \"Sbmeirow\"\n",
      "Error on \"Scanlan\"\n",
      "Error on \"Scapulus\"\n",
      "Error on \"SchutteGod\"\n",
      "Error on \"Searingjet\"\n",
      "Error on \"Ser Amantio di Nicolao\"\n",
      "Error on \"Shafi Azim\"\n",
      "Error on \"Shakehandsman\"\n",
      "Error on \"Shawn in Montreal\"\n",
      "Error on \"Shimlaites\"\n",
      "Error on \"Shimunogora\"\n",
      "Error on \"Shortride\"\n",
      "Error on \"Silvarado98\"\n",
      "Error on \"SilverSurfingSerpent\"\n",
      "Error on \"Sj\"\n",
      "Error on \"Skm989898\"\n",
      "Error on \"Skubydoo\"\n",
      "Error on \"Slated-grace\"\n",
      "Error on \"Sleeping is fun\"\n",
      "Error on \"SlimVirgin\"\n",
      "Error on \"SlitherySentinel\"\n",
      "Error on \"Smallbones\"\n",
      "Error on \"Smalljim\"\n",
      "Error on \"Snakeskinsam\"\n",
      "Error on \"SoloWing3844\"\n",
      "Error on \"SomeAverageJoe\"\n",
      "Error on \"Someguy432\"\n",
      "Error on \"SounderBruce\"\n",
      "Error on \"Sovietmessiah\"\n",
      "Error on \"Speartackler\"\n",
      "Error on \"Sphilbrick\"\n",
      "Error on \"Srednaus Lenoroc\"\n",
      "Error on \"Srednuas Lenoroc\"\n",
      "Error on \"Srich32977\"\n",
      "Error on \"Ssilvers\"\n",
      "Error on \"Sskulnik\"\n",
      "Error on \"StAnselm\"\n",
      "Error on \"Stanley Steemer\"\n",
      "Error on \"Starcheerspeaksnewslostwars\"\n",
      "Error on \"Steel1943\"\n",
      "Error on \"Steeletrap\"\n",
      "Error on \"Stephen Hui\"\n",
      "Error on \"Stevo D\"\n",
      "Error on \"Stikkyy\"\n",
      "Error on \"Straussardete\"\n",
      "Error on \"StuRat\"\n",
      "Error on \"SummerPhDv2.0\"\n",
      "Error on \"SuperHamster\"\n",
      "Error on \"Surachit\"\n",
      "Error on \"Surtsicna\"\n",
      "Error on \"Swagger14\"\n",
      "Error on \"Swanson14\"\n",
      "Error on \"Srgio Itigo\"\n",
      "Error on \"Sawomir Biay\"\n",
      "Error on \"TDMfan23!\"\n",
      "Error on \"TJH2018\"\n",
      "Error on \"TUFKAAP\"\n",
      "Error on \"TVC 15\"\n",
      "Error on \"Tabletop\"\n",
      "Error on \"Taftroad19\"\n",
      "Error on \"Tahc\"\n",
      "Error on \"Tala hayat\"\n",
      "Error on \"Tassedethe\"\n",
      "Error on \"Tbhotch\"\n",
      "Error on \"Techtitannews\"\n",
      "Error on \"Tedperl\"\n",
      "Error on \"Telfordbuck\"\n",
      "Error on \"TenPoundHammer\"\n",
      "Error on \"Tenebrae\"\n",
      "Error on \"Tenor12\"\n",
      "At position: 2400\n",
      "Error on \"Tewapack\"\n",
      "Error on \"Texas Cactus\"\n",
      "Error on \"TexasMan34\"\n",
      "Error on \"ThaiWanIII\"\n",
      "Error on \"Thalia42\"\n",
      "Error on \"The Almightey Drill\"\n",
      "Error on \"The Anome\"\n",
      "Error on \"The Banner\"\n",
      "Error on \"The Independent Greek 100\"\n",
      "Error on \"The Quixotic Potato\"\n",
      "Error on \"The Rambling Man\"\n",
      "Error on \"The Sackinator\"\n",
      "Error on \"The ed17\"\n",
      "Error on \"The1337gamer\"\n",
      "Error on \"TheGracefulSlick\"\n",
      "Error on \"TheLongTone\"\n",
      "Error on \"ThePlane11\"\n",
      "Error on \"ThePlatypusofDoom\"\n",
      "Error on \"Thegoldenconciseencyclopediaofmammals\"\n",
      "Error on \"Themikebest\"\n",
      "Error on \"Thenabster126\"\n",
      "Error on \"Theroadislong\"\n",
      "Error on \"Thirdright\"\n",
      "Error on \"This is Paul\"\n",
      "Error on \"Thundermaker\"\n",
      "Error on \"Tiller54\"\n",
      "Error on \"Tillmanlanyi\"\n",
      "Error on \"Tim!\"\n",
      "Error on \"Timeless Days\"\n",
      "Error on \"Tinton5\"\n",
      "Error on \"Titodutta\"\n",
      "Error on \"Tokyogirl79\"\n",
      "Error on \"Tom2123\"\n",
      "Error on \"TommyBoy\"\n",
      "Error on \"Tommybrae\"\n",
      "Error on \"Tompop888\"\n",
      "Error on \"Tomruen\"\n",
      "Error on \"Tomwood0\"\n",
      "Error on \"Tony1\"\n",
      "Error on \"TonyTheTiger\"\n",
      "Error on \"Tonybins\"\n",
      "Error on \"Topbanana\"\n",
      "Error on \"Tophe2t\"\n",
      "Error on \"Torchiest\"\n",
      "Error on \"ToriJana\"\n",
      "Error on \"Tornado chaser\"\n",
      "Error on \"Torrie1975\"\n",
      "Error on \"Tpbradbury\"\n",
      "Error on \"Trepcost\"\n",
      "Error on \"Triplecaa\"\n",
      "Error on \"Trivialist\"\n",
      "Error on \"Truthsort\"\n",
      "Error on \"Turboliner\"\n",
      "Error on \"Tyrol5\"\n",
      "Error on \"UW Dawgs\"\n",
      "Error on \"Ulric1313\"\n",
      "Error on \"Unendin\"\n",
      "Error on \"Unreal7\"\n",
      "Error on \"User170\"\n",
      "Error on \"User38479\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on \"Usernamen1\"\n",
      "Error on \"Utbindas\"\n",
      "Error on \"Velostodon\"\n",
      "Error on \"Versus001\"\n",
      "Error on \"Vidatafazoli\"\n",
      "Error on \"Vincelord\"\n",
      "Error on \"Vincent5\"\n",
      "Error on \"ViperSnake151\"\n",
      "Error on \"Vjmlhds\"\n",
      "Error on \"VoltaireEditor2016\"\n",
      "Error on \"Volunteer Marek\"\n",
      "Error on \"Vrrajkum\"\n",
      "Error on \"Vsmith\"\n",
      "Error on \"WWGB\"\n",
      "Error on \"Waffles9761\"\n",
      "Error on \"Washingtonediter\"\n",
      "Error on \"Wavelength\"\n",
      "Error on \"Wayne Elgin\"\n",
      "Error on \"Wbm1058\"\n",
      "Error on \"WeaponOfChoice1\"\n",
      "Error on \"Weather28540\"\n",
      "Error on \"WereSpielChequers\"\n",
      "Error on \"Werldwayd\"\n",
      "Error on \"What cat?\"\n",
      "Error on \"WhatsUpWorld\"\n",
      "Error on \"WhisperToMe\"\n",
      "Error on \"Widefox\"\n",
      "Error on \"Widr\"\n",
      "Error on \"WikiDan61\"\n",
      "Error on \"Wikipedical\"\n",
      "Error on \"Wikipelli\"\n",
      "Error on \"Wikishovel\"\n",
      "Error on \"William Avery\"\n",
      "Error on \"WilliamJE\"\n",
      "Error on \"Woodensuperman\"\n",
      "At position: 2700\n",
      "Error on \"Woodstein52\"\n",
      "Error on \"Wpeneditor\"\n",
      "Error on \"Xandahar\"\n",
      "Error on \"Xezbeth\"\n",
      "Error on \"Xin Deui\"\n",
      "Error on \"Y2kcrazyjoker4\"\n",
      "Error on \"Yamaguchi\"\n",
      "Error on \"Yintan\"\n",
      "Error on \"Ymblanter\"\n",
      "Error on \"Yourmanstan\"\n",
      "Error on \"YoursT\"\n",
      "Error on \"Yujeshkc\"\n",
      "Error on \"Yulia Romero\"\n",
      "Error on \"Yvarta\"\n",
      "Error on \"ZSJUSA\"\n",
      "Error on \"Zakipedia\"\n",
      "Error on \"ZappaOMati\"\n",
      "Error on \"Zeddawg\"\n",
      "Error on \"ZgortBX\"\n",
      "Error on \"Zigzig20s\"\n",
      "Error on \"Zyxw\"\n",
      "Error on \"Zzyzx11\"\n",
      "Error on \"rico\"\n",
      "Error on \"\"\n",
      "Error on \" \"\n",
      "Error on \"  \"\n",
      "Error on \"62\"\n",
      "Error on \"\"\n",
      "Error on \"Golf\"\n",
      "Error on \"\"\n",
      "Error on \"\"\n"
     ]
    }
   ],
   "source": [
    "usercontribs_dict = {}\n",
    "#usercontribs_errors = []\n",
    "\n",
    "for i,_payload in enumerate(active_both_userinfo[165:]):\n",
    "    if 'name' in _payload:\n",
    "        try:\n",
    "            _username = _payload['name']\n",
    "            _id = _payload['userid']\n",
    "            _df = get_user_contributions(_username,start=pd.Timestamp('2013-01-01'),stop=pd.Timestamp('2017-11-09'))\n",
    "            _df.to_csv(_dir + 'Data/Users/{0}.csv'.format(_id))\n",
    "            time.sleep(.5)\n",
    "            usercontribs_dict[_username] = _df\n",
    "            if i % 300 == 0:\n",
    "                print(\"At position: {0}\".format(i))\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            print(\"Error on \\\"{0}\\\"\".format(_payload['name']))\n",
    "            usercontribs_errors.append(_payload['name'])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10001499.csv'"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_contribs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>minor</th>\n",
       "      <th>new</th>\n",
       "      <th>ns</th>\n",
       "      <th>pageid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>revid</th>\n",
       "      <th>size</th>\n",
       "      <th>sizediff</th>\n",
       "      <th>suppressed</th>\n",
       "      <th>texthidden</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>top</th>\n",
       "      <th>user</th>\n",
       "      <th>userid</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/* Japanese position */ c/e</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>29020730</td>\n",
       "      <td>530583585</td>\n",
       "      <td>530889949</td>\n",
       "      <td>108592</td>\n",
       "      <td>574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-02 08:58:59</td>\n",
       "      <td>Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/* Japanese position */ moved a citation from ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>29020730</td>\n",
       "      <td>530889949</td>\n",
       "      <td>530890742</td>\n",
       "      <td>108466</td>\n",
       "      <td>-126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-02 09:08:37</td>\n",
       "      <td>Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/* Question about the recent major edit */ bel...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>530551814</td>\n",
       "      <td>531208987</td>\n",
       "      <td>24573</td>\n",
       "      <td>1714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-04 04:13:24</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reverted edits by [[Special:Contributions/ 67....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>330979</td>\n",
       "      <td>531235799</td>\n",
       "      <td>531240217</td>\n",
       "      <td>7455</td>\n",
       "      <td>-556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-04 09:32:59</td>\n",
       "      <td>Jap</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/* January 2013 */ new section</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>38116817</td>\n",
       "      <td>0</td>\n",
       "      <td>531240283</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-04 09:33:54</td>\n",
       "      <td>User talk:67.225.9.144</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Undid revision 531860852 by [[Special:Contribu...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>341418</td>\n",
       "      <td>531860852</td>\n",
       "      <td>531882538</td>\n",
       "      <td>97504</td>\n",
       "      <td>1121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 02:16:32</td>\n",
       "      <td>Korea under Japanese rule</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/* Japanese migration and land confiscation */...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>341418</td>\n",
       "      <td>531882538</td>\n",
       "      <td>531883450</td>\n",
       "      <td>97992</td>\n",
       "      <td>488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 02:24:30</td>\n",
       "      <td>Korea under Japanese rule</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/* Airspace incursion */ The wording in inappr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>531890532</td>\n",
       "      <td>531893996</td>\n",
       "      <td>27627</td>\n",
       "      <td>525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 03:51:56</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/* Airspace incursion */ more logically explained</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>531893996</td>\n",
       "      <td>531919074</td>\n",
       "      <td>28206</td>\n",
       "      <td>579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 07:45:12</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/* Airspace incursion */ fix</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>531919074</td>\n",
       "      <td>531921889</td>\n",
       "      <td>28209</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 08:16:39</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/* Airspace incursion */ administer or control?</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>531925879</td>\n",
       "      <td>531929380</td>\n",
       "      <td>30346</td>\n",
       "      <td>1060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 09:46:52</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/* Airspace incursion */ +</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>531930041</td>\n",
       "      <td>531930130</td>\n",
       "      <td>31024</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 09:55:54</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/* Airspace incursion */+</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>531930889</td>\n",
       "      <td>531934909</td>\n",
       "      <td>31216</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-08 10:53:46</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Reverted edits by [[Special:Contributions/ Par...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>65734</td>\n",
       "      <td>532475154</td>\n",
       "      <td>532477712</td>\n",
       "      <td>30160</td>\n",
       "      <td>-2541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 02:54:20</td>\n",
       "      <td>Bushido</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/* Etymology */ new section</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1227361</td>\n",
       "      <td>514048890</td>\n",
       "      <td>532485712</td>\n",
       "      <td>16484</td>\n",
       "      <td>615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 04:08:58</td>\n",
       "      <td>Talk:Bushido</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>revert further. see talk.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>65734</td>\n",
       "      <td>532477712</td>\n",
       "      <td>532485954</td>\n",
       "      <td>30122</td>\n",
       "      <td>-38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 04:11:40</td>\n",
       "      <td>Bushido</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/* Etymology */ fix</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1227361</td>\n",
       "      <td>532485712</td>\n",
       "      <td>532486198</td>\n",
       "      <td>16484</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 04:14:23</td>\n",
       "      <td>Talk:Bushido</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Undid revision 528343881 by [[Special:Contribu...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>65734</td>\n",
       "      <td>532485954</td>\n",
       "      <td>532487087</td>\n",
       "      <td>30040</td>\n",
       "      <td>-82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 04:24:58</td>\n",
       "      <td>Bushido</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/* The Chinese government has seized \"750,000 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>532506455</td>\n",
       "      <td>532521047</td>\n",
       "      <td>36224</td>\n",
       "      <td>1075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 10:52:15</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/* Sangoku Tsu-ran Zusetsu (??????) */ comment</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>532522304</td>\n",
       "      <td>532522783</td>\n",
       "      <td>36897</td>\n",
       "      <td>547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 11:11:50</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/* Sangoku Tsu-ran Zusetsu (??????) */ fix</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>29043602</td>\n",
       "      <td>532522783</td>\n",
       "      <td>532524178</td>\n",
       "      <td>36899</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-11 11:26:14</td>\n",
       "      <td>Talk:Senkaku Islands dispute</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Undid revision 532609763 by [[Special:Contribu...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>330979</td>\n",
       "      <td>532609763</td>\n",
       "      <td>532672564</td>\n",
       "      <td>7455</td>\n",
       "      <td>-556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-12 08:57:14</td>\n",
       "      <td>Jap</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/* Block review */ new section</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5149102</td>\n",
       "      <td>532673863</td>\n",
       "      <td>532674214</td>\n",
       "      <td>311330</td>\n",
       "      <td>1030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-12 09:38:46</td>\n",
       "      <td>Wikipedia:Administrators' noticeboard</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/* Block review */ fix</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5149102</td>\n",
       "      <td>532674214</td>\n",
       "      <td>532674343</td>\n",
       "      <td>311330</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-12 09:40:24</td>\n",
       "      <td>Wikipedia:Administrators' noticeboard</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/* AN notice */ new section</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>13604442</td>\n",
       "      <td>532606392</td>\n",
       "      <td>532674473</td>\n",
       "      <td>9889</td>\n",
       "      <td>345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-12 09:41:57</td>\n",
       "      <td>User talk:Future Perfect at Sunrise</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/* AN notice */ new section</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>33133838</td>\n",
       "      <td>532541368</td>\n",
       "      <td>532674573</td>\n",
       "      <td>19189</td>\n",
       "      <td>344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-12 09:43:27</td>\n",
       "      <td>User talk:Wingwrong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/* Block review */ denialist?</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5149102</td>\n",
       "      <td>532832468</td>\n",
       "      <td>532833515</td>\n",
       "      <td>314511</td>\n",
       "      <td>1202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-13 08:56:05</td>\n",
       "      <td>Wikipedia:Administrators' noticeboard</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/* Block review */ reply</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5149102</td>\n",
       "      <td>532834743</td>\n",
       "      <td>532840974</td>\n",
       "      <td>315783</td>\n",
       "      <td>450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-13 10:15:43</td>\n",
       "      <td>Wikipedia:Administrators' noticeboard</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/* Block review */ +</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5149102</td>\n",
       "      <td>532840974</td>\n",
       "      <td>532841625</td>\n",
       "      <td>315871</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-13 10:23:02</td>\n",
       "      <td>Wikipedia:Administrators' noticeboard</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/* Block review */ fix</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5149102</td>\n",
       "      <td>532841625</td>\n",
       "      <td>532842062</td>\n",
       "      <td>315874</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-13 10:27:14</td>\n",
       "      <td>Wikipedia:Administrators' noticeboard</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2013-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>/* History */ added a 2017 study</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>46176194</td>\n",
       "      <td>814768908</td>\n",
       "      <td>817399647</td>\n",
       "      <td>36720</td>\n",
       "      <td>1114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-28 04:11:09</td>\n",
       "      <td>King cherry</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>/* Fire growth and containment progress */ rep...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>55972902</td>\n",
       "      <td>817387714</td>\n",
       "      <td>817401732</td>\n",
       "      <td>68113</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-28 04:31:13</td>\n",
       "      <td>Thomas Fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>/* Putative parental species */ added a 2017 r...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>46176194</td>\n",
       "      <td>817399647</td>\n",
       "      <td>817409461</td>\n",
       "      <td>37348</td>\n",
       "      <td>628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-28 05:56:54</td>\n",
       "      <td>King cherry</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>[[WP:AES|?]]Redirected page to [[JapanSouth K...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>56167106</td>\n",
       "      <td>0</td>\n",
       "      <td>817707926</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-30 02:53:38</td>\n",
       "      <td>Korea fatigue</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>added a map</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56158906</td>\n",
       "      <td>817744072</td>\n",
       "      <td>817745922</td>\n",
       "      <td>5481</td>\n",
       "      <td>491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-30 09:18:11</td>\n",
       "      <td>2017 Bronx apartment fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>section</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56158906</td>\n",
       "      <td>817745922</td>\n",
       "      <td>817746445</td>\n",
       "      <td>5504</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-30 09:23:29</td>\n",
       "      <td>2017 Bronx apartment fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>moved up</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56158906</td>\n",
       "      <td>817746445</td>\n",
       "      <td>817749972</td>\n",
       "      <td>5506</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-30 10:01:55</td>\n",
       "      <td>2017 Bronx apartment fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>added an image</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>817846607</td>\n",
       "      <td>817860169</td>\n",
       "      <td>9914</td>\n",
       "      <td>387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-31 00:15:38</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>added  one</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>817860169</td>\n",
       "      <td>817860578</td>\n",
       "      <td>10025</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-31 00:18:52</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>added a ref</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>817860578</td>\n",
       "      <td>817861163</td>\n",
       "      <td>10289</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-31 00:23:03</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2017-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>adjust the width</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>817861163</td>\n",
       "      <td>818066702</td>\n",
       "      <td>10309</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 09:14:55</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>Reverted 1 edit by [[Special:Contributions/198...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>26067550</td>\n",
       "      <td>818066786</td>\n",
       "      <td>818066999</td>\n",
       "      <td>7924</td>\n",
       "      <td>-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 09:16:59</td>\n",
       "      <td>List of the largest trading partners of China</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>fixed citations</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>818066702</td>\n",
       "      <td>818067796</td>\n",
       "      <td>10368</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 09:29:39</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>c/e</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>818067796</td>\n",
       "      <td>818072725</td>\n",
       "      <td>10377</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 10:33:17</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>compound word of guk and Philopon</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56078657</td>\n",
       "      <td>818072725</td>\n",
       "      <td>818075825</td>\n",
       "      <td>10463</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 11:16:54</td>\n",
       "      <td>Gukppong</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>/* Wildfire maps */ dot size reduced</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>53931534</td>\n",
       "      <td>818196677</td>\n",
       "      <td>818206185</td>\n",
       "      <td>44560</td>\n",
       "      <td>-301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-02 06:23:35</td>\n",
       "      <td>2017 California wildfires</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>/* Fire growth and containment progress */ cla...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>55972902</td>\n",
       "      <td>818237719</td>\n",
       "      <td>818241495</td>\n",
       "      <td>73237</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-02 12:16:41</td>\n",
       "      <td>Thomas Fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>\"gas\" stove, \"basement\" apartment</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56158906</td>\n",
       "      <td>818484382</td>\n",
       "      <td>818489319</td>\n",
       "      <td>5531</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-03 21:32:33</td>\n",
       "      <td>2017 Bronx apartment fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>\"kitchen\" stove</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56158906</td>\n",
       "      <td>818489503</td>\n",
       "      <td>818492901</td>\n",
       "      <td>5550</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-03 21:58:35</td>\n",
       "      <td>2017 Bronx apartment fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>spread up \"the stairwell\"</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56158906</td>\n",
       "      <td>818492901</td>\n",
       "      <td>818493853</td>\n",
       "      <td>5567</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-03 22:05:03</td>\n",
       "      <td>2017 Bronx apartment fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>Updated the world map</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>48925754</td>\n",
       "      <td>818495312</td>\n",
       "      <td>818679297</td>\n",
       "      <td>165408</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-04 23:20:15</td>\n",
       "      <td>List of earthquakes in 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>/* List of Hwasong-12 tests */ added a coord</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>54089641</td>\n",
       "      <td>818058631</td>\n",
       "      <td>818708201</td>\n",
       "      <td>11277</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05 03:35:23</td>\n",
       "      <td>Hwasong-12</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>/* Security vulnerabilities */ correction</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>319504</td>\n",
       "      <td>818740667</td>\n",
       "      <td>818745725</td>\n",
       "      <td>9398</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05 09:26:10</td>\n",
       "      <td>Speculative execution</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>/* Security vulnerabilities */ replaced a source</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>319504</td>\n",
       "      <td>818745725</td>\n",
       "      <td>818746000</td>\n",
       "      <td>9408</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05 09:29:41</td>\n",
       "      <td>Speculative execution</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>/* Cache entry structure */ c/e</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>849181</td>\n",
       "      <td>814275314</td>\n",
       "      <td>818936555</td>\n",
       "      <td>82507</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-06 13:34:20</td>\n",
       "      <td>CPU cache</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>/* Fire growth and containment progress */ sp</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>55972902</td>\n",
       "      <td>819000898</td>\n",
       "      <td>819004589</td>\n",
       "      <td>75204</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-06 21:19:11</td>\n",
       "      <td>Thomas Fire</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>added hanja</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>55281799</td>\n",
       "      <td>818760395</td>\n",
       "      <td>819011449</td>\n",
       "      <td>20161</td>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-06 22:09:53</td>\n",
       "      <td>Gapjil</td>\n",
       "      <td>False</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>Replaced a map</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>140461</td>\n",
       "      <td>819353450</td>\n",
       "      <td>819430421</td>\n",
       "      <td>63196</td>\n",
       "      <td>-234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 09:40:24</td>\n",
       "      <td>Lists of earthquakes</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>/* Major earthquakes */ added a map</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>10106</td>\n",
       "      <td>817603384</td>\n",
       "      <td>819430596</td>\n",
       "      <td>66696</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 09:41:55</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>/* Implementation */ added more implementation...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>56160987</td>\n",
       "      <td>819425878</td>\n",
       "      <td>819441545</td>\n",
       "      <td>14176</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-09 11:28:27</td>\n",
       "      <td>Kernel page-table isolation</td>\n",
       "      <td>True</td>\n",
       "      <td>Phoenix7777</td>\n",
       "      <td>10001499</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  minor    new  ns  \\\n",
       "0                           /* Japanese position */ c/e  False  False   0   \n",
       "1     /* Japanese position */ moved a citation from ...  False  False   0   \n",
       "2     /* Question about the recent major edit */ bel...  False  False   1   \n",
       "3     Reverted edits by [[Special:Contributions/ 67....  False  False   0   \n",
       "4                        /* January 2013 */ new section  False   True   3   \n",
       "5     Undid revision 531860852 by [[Special:Contribu...  False  False   0   \n",
       "6     /* Japanese migration and land confiscation */...  False  False   0   \n",
       "7     /* Airspace incursion */ The wording in inappr...  False  False   1   \n",
       "8     /* Airspace incursion */ more logically explained  False  False   1   \n",
       "9                          /* Airspace incursion */ fix  False  False   1   \n",
       "10      /* Airspace incursion */ administer or control?  False  False   1   \n",
       "11                           /* Airspace incursion */ +  False  False   1   \n",
       "12                            /* Airspace incursion */+  False  False   1   \n",
       "13    Reverted edits by [[Special:Contributions/ Par...  False  False   0   \n",
       "14                          /* Etymology */ new section  False  False   1   \n",
       "15                            revert further. see talk.  False  False   0   \n",
       "16                                  /* Etymology */ fix  False  False   1   \n",
       "17    Undid revision 528343881 by [[Special:Contribu...  False  False   0   \n",
       "18    /* The Chinese government has seized \"750,000 ...  False  False   1   \n",
       "19       /* Sangoku Tsu-ran Zusetsu (??????) */ comment  False  False   1   \n",
       "20           /* Sangoku Tsu-ran Zusetsu (??????) */ fix  False  False   1   \n",
       "21    Undid revision 532609763 by [[Special:Contribu...  False  False   0   \n",
       "22                       /* Block review */ new section  False  False   4   \n",
       "23                               /* Block review */ fix  False  False   4   \n",
       "24                          /* AN notice */ new section  False  False   3   \n",
       "25                          /* AN notice */ new section  False  False   3   \n",
       "26                        /* Block review */ denialist?  False  False   4   \n",
       "27                             /* Block review */ reply  False  False   4   \n",
       "28                                 /* Block review */ +  False  False   4   \n",
       "29                               /* Block review */ fix  False  False   4   \n",
       "...                                                 ...    ...    ...  ..   \n",
       "4868                   /* History */ added a 2017 study  False  False   0   \n",
       "4869  /* Fire growth and containment progress */ rep...  False  False   0   \n",
       "4870  /* Putative parental species */ added a 2017 r...  False  False   0   \n",
       "4871  [[WP:AES|?]]Redirected page to [[JapanSouth K...  False   True   0   \n",
       "4872                                        added a map  False  False   0   \n",
       "4873                                            section  False  False   0   \n",
       "4874                                           moved up  False  False   0   \n",
       "4875                                     added an image  False  False   0   \n",
       "4876                                         added  one  False  False   0   \n",
       "4877                                        added a ref  False  False   0   \n",
       "4878                                   adjust the width  False  False   0   \n",
       "4879  Reverted 1 edit by [[Special:Contributions/198...  False  False   0   \n",
       "4880                                    fixed citations  False  False   0   \n",
       "4881                                                c/e  False  False   0   \n",
       "4882                  compound word of guk and Philopon  False  False   0   \n",
       "4883               /* Wildfire maps */ dot size reduced  False  False   0   \n",
       "4884  /* Fire growth and containment progress */ cla...  False  False   0   \n",
       "4885                  \"gas\" stove, \"basement\" apartment  False  False   0   \n",
       "4886                                    \"kitchen\" stove  False  False   0   \n",
       "4887                          spread up \"the stairwell\"  False  False   0   \n",
       "4888                              Updated the world map  False  False   0   \n",
       "4889       /* List of Hwasong-12 tests */ added a coord  False  False   0   \n",
       "4890          /* Security vulnerabilities */ correction  False  False   0   \n",
       "4891   /* Security vulnerabilities */ replaced a source  False  False   0   \n",
       "4892                    /* Cache entry structure */ c/e  False  False   0   \n",
       "4893      /* Fire growth and containment progress */ sp  False  False   0   \n",
       "4894                                        added hanja  False  False   0   \n",
       "4895                                     Replaced a map  False  False   0   \n",
       "4896                /* Major earthquakes */ added a map  False  False   0   \n",
       "4897  /* Implementation */ added more implementation...  False  False   0   \n",
       "\n",
       "        pageid   parentid      revid    size  sizediff suppressed texthidden  \\\n",
       "0     29020730  530583585  530889949  108592       574        NaN        NaN   \n",
       "1     29020730  530889949  530890742  108466      -126        NaN        NaN   \n",
       "2     29043602  530551814  531208987   24573      1714        NaN        NaN   \n",
       "3       330979  531235799  531240217    7455      -556        NaN        NaN   \n",
       "4     38116817          0  531240283     137       137        NaN        NaN   \n",
       "5       341418  531860852  531882538   97504      1121        NaN        NaN   \n",
       "6       341418  531882538  531883450   97992       488        NaN        NaN   \n",
       "7     29043602  531890532  531893996   27627       525        NaN        NaN   \n",
       "8     29043602  531893996  531919074   28206       579        NaN        NaN   \n",
       "9     29043602  531919074  531921889   28209         3        NaN        NaN   \n",
       "10    29043602  531925879  531929380   30346      1060        NaN        NaN   \n",
       "11    29043602  531930041  531930130   31024       106        NaN        NaN   \n",
       "12    29043602  531930889  531934909   31216       192        NaN        NaN   \n",
       "13       65734  532475154  532477712   30160     -2541        NaN        NaN   \n",
       "14     1227361  514048890  532485712   16484       615        NaN        NaN   \n",
       "15       65734  532477712  532485954   30122       -38        NaN        NaN   \n",
       "16     1227361  532485712  532486198   16484         0        NaN        NaN   \n",
       "17       65734  532485954  532487087   30040       -82        NaN        NaN   \n",
       "18    29043602  532506455  532521047   36224      1075        NaN        NaN   \n",
       "19    29043602  532522304  532522783   36897       547        NaN        NaN   \n",
       "20    29043602  532522783  532524178   36899         2        NaN        NaN   \n",
       "21      330979  532609763  532672564    7455      -556        NaN        NaN   \n",
       "22     5149102  532673863  532674214  311330      1030        NaN        NaN   \n",
       "23     5149102  532674214  532674343  311330         0        NaN        NaN   \n",
       "24    13604442  532606392  532674473    9889       345        NaN        NaN   \n",
       "25    33133838  532541368  532674573   19189       344        NaN        NaN   \n",
       "26     5149102  532832468  532833515  314511      1202        NaN        NaN   \n",
       "27     5149102  532834743  532840974  315783       450        NaN        NaN   \n",
       "28     5149102  532840974  532841625  315871        88        NaN        NaN   \n",
       "29     5149102  532841625  532842062  315874         3        NaN        NaN   \n",
       "...        ...        ...        ...     ...       ...        ...        ...   \n",
       "4868  46176194  814768908  817399647   36720      1114        NaN        NaN   \n",
       "4869  55972902  817387714  817401732   68113        43        NaN        NaN   \n",
       "4870  46176194  817399647  817409461   37348       628        NaN        NaN   \n",
       "4871  56167106          0  817707926      43        43        NaN        NaN   \n",
       "4872  56158906  817744072  817745922    5481       491        NaN        NaN   \n",
       "4873  56158906  817745922  817746445    5504        23        NaN        NaN   \n",
       "4874  56158906  817746445  817749972    5506         2        NaN        NaN   \n",
       "4875  56078657  817846607  817860169    9914       387        NaN        NaN   \n",
       "4876  56078657  817860169  817860578   10025       111        NaN        NaN   \n",
       "4877  56078657  817860578  817861163   10289       264        NaN        NaN   \n",
       "4878  56078657  817861163  818066702   10309        20        NaN        NaN   \n",
       "4879  26067550  818066786  818066999    7924        -7        NaN        NaN   \n",
       "4880  56078657  818066702  818067796   10368        59        NaN        NaN   \n",
       "4881  56078657  818067796  818072725   10377         9        NaN        NaN   \n",
       "4882  56078657  818072725  818075825   10463        86        NaN        NaN   \n",
       "4883  53931534  818196677  818206185   44560      -301        NaN        NaN   \n",
       "4884  55972902  818237719  818241495   73237       155        NaN        NaN   \n",
       "4885  56158906  818484382  818489319    5531        13        NaN        NaN   \n",
       "4886  56158906  818489503  818492901    5550        12        NaN        NaN   \n",
       "4887  56158906  818492901  818493853    5567        17        NaN        NaN   \n",
       "4888  48925754  818495312  818679297  165408         0        NaN        NaN   \n",
       "4889  54089641  818058631  818708201   11277        30        NaN        NaN   \n",
       "4890    319504  818740667  818745725    9398        -2        NaN        NaN   \n",
       "4891    319504  818745725  818746000    9408        10        NaN        NaN   \n",
       "4892    849181  814275314  818936555   82507        26        NaN        NaN   \n",
       "4893  55972902  819000898  819004589   75204         1        NaN        NaN   \n",
       "4894  55281799  818760395  819011449   20161       274        NaN        NaN   \n",
       "4895    140461  819353450  819430421   63196      -234        NaN        NaN   \n",
       "4896     10106  817603384  819430596   66696        94        NaN        NaN   \n",
       "4897  56160987  819425878  819441545   14176       349        NaN        NaN   \n",
       "\n",
       "                timestamp                                          title  \\\n",
       "0     2013-01-02 08:58:59                        Senkaku Islands dispute   \n",
       "1     2013-01-02 09:08:37                        Senkaku Islands dispute   \n",
       "2     2013-01-04 04:13:24                   Talk:Senkaku Islands dispute   \n",
       "3     2013-01-04 09:32:59                                            Jap   \n",
       "4     2013-01-04 09:33:54                         User talk:67.225.9.144   \n",
       "5     2013-01-08 02:16:32                      Korea under Japanese rule   \n",
       "6     2013-01-08 02:24:30                      Korea under Japanese rule   \n",
       "7     2013-01-08 03:51:56                   Talk:Senkaku Islands dispute   \n",
       "8     2013-01-08 07:45:12                   Talk:Senkaku Islands dispute   \n",
       "9     2013-01-08 08:16:39                   Talk:Senkaku Islands dispute   \n",
       "10    2013-01-08 09:46:52                   Talk:Senkaku Islands dispute   \n",
       "11    2013-01-08 09:55:54                   Talk:Senkaku Islands dispute   \n",
       "12    2013-01-08 10:53:46                   Talk:Senkaku Islands dispute   \n",
       "13    2013-01-11 02:54:20                                        Bushido   \n",
       "14    2013-01-11 04:08:58                                   Talk:Bushido   \n",
       "15    2013-01-11 04:11:40                                        Bushido   \n",
       "16    2013-01-11 04:14:23                                   Talk:Bushido   \n",
       "17    2013-01-11 04:24:58                                        Bushido   \n",
       "18    2013-01-11 10:52:15                   Talk:Senkaku Islands dispute   \n",
       "19    2013-01-11 11:11:50                   Talk:Senkaku Islands dispute   \n",
       "20    2013-01-11 11:26:14                   Talk:Senkaku Islands dispute   \n",
       "21    2013-01-12 08:57:14                                            Jap   \n",
       "22    2013-01-12 09:38:46          Wikipedia:Administrators' noticeboard   \n",
       "23    2013-01-12 09:40:24          Wikipedia:Administrators' noticeboard   \n",
       "24    2013-01-12 09:41:57            User talk:Future Perfect at Sunrise   \n",
       "25    2013-01-12 09:43:27                            User talk:Wingwrong   \n",
       "26    2013-01-13 08:56:05          Wikipedia:Administrators' noticeboard   \n",
       "27    2013-01-13 10:15:43          Wikipedia:Administrators' noticeboard   \n",
       "28    2013-01-13 10:23:02          Wikipedia:Administrators' noticeboard   \n",
       "29    2013-01-13 10:27:14          Wikipedia:Administrators' noticeboard   \n",
       "...                   ...                                            ...   \n",
       "4868  2017-12-28 04:11:09                                    King cherry   \n",
       "4869  2017-12-28 04:31:13                                    Thomas Fire   \n",
       "4870  2017-12-28 05:56:54                                    King cherry   \n",
       "4871  2017-12-30 02:53:38                                  Korea fatigue   \n",
       "4872  2017-12-30 09:18:11                      2017 Bronx apartment fire   \n",
       "4873  2017-12-30 09:23:29                      2017 Bronx apartment fire   \n",
       "4874  2017-12-30 10:01:55                      2017 Bronx apartment fire   \n",
       "4875  2017-12-31 00:15:38                                       Gukppong   \n",
       "4876  2017-12-31 00:18:52                                       Gukppong   \n",
       "4877  2017-12-31 00:23:03                                       Gukppong   \n",
       "4878  2018-01-01 09:14:55                                       Gukppong   \n",
       "4879  2018-01-01 09:16:59  List of the largest trading partners of China   \n",
       "4880  2018-01-01 09:29:39                                       Gukppong   \n",
       "4881  2018-01-01 10:33:17                                       Gukppong   \n",
       "4882  2018-01-01 11:16:54                                       Gukppong   \n",
       "4883  2018-01-02 06:23:35                      2017 California wildfires   \n",
       "4884  2018-01-02 12:16:41                                    Thomas Fire   \n",
       "4885  2018-01-03 21:32:33                      2017 Bronx apartment fire   \n",
       "4886  2018-01-03 21:58:35                      2017 Bronx apartment fire   \n",
       "4887  2018-01-03 22:05:03                      2017 Bronx apartment fire   \n",
       "4888  2018-01-04 23:20:15                    List of earthquakes in 2017   \n",
       "4889  2018-01-05 03:35:23                                     Hwasong-12   \n",
       "4890  2018-01-05 09:26:10                          Speculative execution   \n",
       "4891  2018-01-05 09:29:41                          Speculative execution   \n",
       "4892  2018-01-06 13:34:20                                      CPU cache   \n",
       "4893  2018-01-06 21:19:11                                    Thomas Fire   \n",
       "4894  2018-01-06 22:09:53                                         Gapjil   \n",
       "4895  2018-01-09 09:40:24                           Lists of earthquakes   \n",
       "4896  2018-01-09 09:41:55                                     Earthquake   \n",
       "4897  2018-01-09 11:28:27                    Kernel page-table isolation   \n",
       "\n",
       "        top         user    userid        date  \n",
       "0     False  Phoenix7777  10001499  2013-01-02  \n",
       "1     False  Phoenix7777  10001499  2013-01-02  \n",
       "2     False  Phoenix7777  10001499  2013-01-04  \n",
       "3     False  Phoenix7777  10001499  2013-01-04  \n",
       "4     False  Phoenix7777  10001499  2013-01-04  \n",
       "5     False  Phoenix7777  10001499  2013-01-08  \n",
       "6     False  Phoenix7777  10001499  2013-01-08  \n",
       "7     False  Phoenix7777  10001499  2013-01-08  \n",
       "8     False  Phoenix7777  10001499  2013-01-08  \n",
       "9     False  Phoenix7777  10001499  2013-01-08  \n",
       "10    False  Phoenix7777  10001499  2013-01-08  \n",
       "11    False  Phoenix7777  10001499  2013-01-08  \n",
       "12    False  Phoenix7777  10001499  2013-01-08  \n",
       "13    False  Phoenix7777  10001499  2013-01-11  \n",
       "14    False  Phoenix7777  10001499  2013-01-11  \n",
       "15    False  Phoenix7777  10001499  2013-01-11  \n",
       "16    False  Phoenix7777  10001499  2013-01-11  \n",
       "17    False  Phoenix7777  10001499  2013-01-11  \n",
       "18    False  Phoenix7777  10001499  2013-01-11  \n",
       "19    False  Phoenix7777  10001499  2013-01-11  \n",
       "20    False  Phoenix7777  10001499  2013-01-11  \n",
       "21    False  Phoenix7777  10001499  2013-01-12  \n",
       "22    False  Phoenix7777  10001499  2013-01-12  \n",
       "23    False  Phoenix7777  10001499  2013-01-12  \n",
       "24    False  Phoenix7777  10001499  2013-01-12  \n",
       "25    False  Phoenix7777  10001499  2013-01-12  \n",
       "26    False  Phoenix7777  10001499  2013-01-13  \n",
       "27    False  Phoenix7777  10001499  2013-01-13  \n",
       "28    False  Phoenix7777  10001499  2013-01-13  \n",
       "29    False  Phoenix7777  10001499  2013-01-13  \n",
       "...     ...          ...       ...         ...  \n",
       "4868  False  Phoenix7777  10001499  2017-12-28  \n",
       "4869  False  Phoenix7777  10001499  2017-12-28  \n",
       "4870   True  Phoenix7777  10001499  2017-12-28  \n",
       "4871   True  Phoenix7777  10001499  2017-12-30  \n",
       "4872  False  Phoenix7777  10001499  2017-12-30  \n",
       "4873  False  Phoenix7777  10001499  2017-12-30  \n",
       "4874  False  Phoenix7777  10001499  2017-12-30  \n",
       "4875  False  Phoenix7777  10001499  2017-12-31  \n",
       "4876  False  Phoenix7777  10001499  2017-12-31  \n",
       "4877  False  Phoenix7777  10001499  2017-12-31  \n",
       "4878  False  Phoenix7777  10001499  2018-01-01  \n",
       "4879  False  Phoenix7777  10001499  2018-01-01  \n",
       "4880  False  Phoenix7777  10001499  2018-01-01  \n",
       "4881  False  Phoenix7777  10001499  2018-01-01  \n",
       "4882   True  Phoenix7777  10001499  2018-01-01  \n",
       "4883  False  Phoenix7777  10001499  2018-01-02  \n",
       "4884  False  Phoenix7777  10001499  2018-01-02  \n",
       "4885  False  Phoenix7777  10001499  2018-01-03  \n",
       "4886  False  Phoenix7777  10001499  2018-01-03  \n",
       "4887  False  Phoenix7777  10001499  2018-01-03  \n",
       "4888  False  Phoenix7777  10001499  2018-01-04  \n",
       "4889   True  Phoenix7777  10001499  2018-01-05  \n",
       "4890  False  Phoenix7777  10001499  2018-01-05  \n",
       "4891  False  Phoenix7777  10001499  2018-01-05  \n",
       "4892  False  Phoenix7777  10001499  2018-01-06  \n",
       "4893  False  Phoenix7777  10001499  2018-01-06  \n",
       "4894  False  Phoenix7777  10001499  2018-01-06  \n",
       "4895   True  Phoenix7777  10001499  2018-01-09  \n",
       "4896   True  Phoenix7777  10001499  2018-01-09  \n",
       "4897   True  Phoenix7777  10001499  2018-01-09  \n",
       "\n",
       "[4898 rows x 17 columns]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.errors.ParserError"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9784415.csv\n"
     ]
    }
   ],
   "source": [
    "user_contribs = os.listdir(_dir + 'Data/Users')\n",
    "usercontribs_l = []\n",
    "\n",
    "for f in user_contribs:\n",
    "    try:\n",
    "        _df = pd.read_csv(_dir + 'Data/Users/' + f,encoding='latin1',index_col=0,parse_dates=['timestamp'],low_memory=False)\n",
    "        try:\n",
    "            _df = _df[_df['timestamp'] > pd.Timestamp('2014-01-01')]\n",
    "        except TypeError:\n",
    "            print(\"Type error in: \" + f)\n",
    "        usercontribs_l.append(_df)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except pd.errors.ParserError:\n",
    "        print(f)\n",
    "        pass\n",
    "\n",
    "all_user_contribs_df = pd.concat(usercontribs_l)\n",
    "all_user_contribs_df.to_csv('active_user_contribs.csv',encoding='utf8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del usercontribs_l\n",
    "del all_user_contribs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clinton_redirect_members = {}\n",
    "trump_redirect_members = {}\n",
    "\n",
    "clinton_errors = []\n",
    "trump_errors = []\n",
    "\n",
    "for member in clinton_category_members:\n",
    "    try:\n",
    "        clinton_redirect_members[member] = get_redirects_linking_here(member)\n",
    "    except:\n",
    "        clinton_errors.append(member)\n",
    "        pass\n",
    "    clinton_redirect_members[member].append(member)\n",
    "    \n",
    "for member in trump_category_members:\n",
    "    try:\n",
    "        trump_redirect_members[member] = get_redirects_linking_here(member)\n",
    "    except:\n",
    "        trump_errors.append(member)\n",
    "        pass\n",
    "    trump_redirect_members[member].append(member)\n",
    "\n",
    "with open('clinton_category_members_redirects.json','w') as f:\n",
    "    json.dump(clinton_redirect_members,f)\n",
    "    \n",
    "with open('trump_category_members_redirects.json','w') as f:\n",
    "    json.dump(trump_redirect_members,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>comment</th>\n",
       "      <th>commenthidden</th>\n",
       "      <th>date</th>\n",
       "      <th>logid</th>\n",
       "      <th>logpage</th>\n",
       "      <th>ns</th>\n",
       "      <th>page</th>\n",
       "      <th>pageid</th>\n",
       "      <th>tags</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patrol</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-13</td>\n",
       "      <td>14781556.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Robert N. Chatigny</td>\n",
       "      <td>16729727.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2008-04-13 13:39:20</td>\n",
       "      <td>Robert N. Chatigny</td>\n",
       "      <td>patrol</td>\n",
       "      <td>DragonflySixtyseven</td>\n",
       "      <td>62058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patrol</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-03-05</td>\n",
       "      <td>20953870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>John R. Tunheim</td>\n",
       "      <td>21834325.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2009-03-05 23:39:29</td>\n",
       "      <td>John R. Tunheim</td>\n",
       "      <td>patrol</td>\n",
       "      <td>Polbot</td>\n",
       "      <td>4477315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delete_redir</td>\n",
       "      <td>[[WP:CSD#G6|G6]]: Deleted to make way for move</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>80218809.0</td>\n",
       "      <td>4067205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bernard Nussbaum</td>\n",
       "      <td>3040825.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2017-01-21 19:05:41</td>\n",
       "      <td>Bernard Nussbaum</td>\n",
       "      <td>delete</td>\n",
       "      <td>Arbor to SJ</td>\n",
       "      <td>4322169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delete</td>\n",
       "      <td>content was: '==Bernard Nussbaum==Former Chief...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-11-26</td>\n",
       "      <td>995795.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bernard Nussbaum</td>\n",
       "      <td>3040825.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2005-11-26 20:16:50</td>\n",
       "      <td>Bernard Nussbaum</td>\n",
       "      <td>delete</td>\n",
       "      <td>Lucky 6.9</td>\n",
       "      <td>51717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>restore</td>\n",
       "      <td>6 revisions restored: restore for merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-04-02</td>\n",
       "      <td>21551687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sidney H. Stein</td>\n",
       "      <td>21832373.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2009-04-02 18:37:03</td>\n",
       "      <td>Sidney H. Stein</td>\n",
       "      <td>delete</td>\n",
       "      <td>BD2412</td>\n",
       "      <td>196446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         action                                            comment  \\\n",
       "0        patrol                                                      \n",
       "1        patrol                                                      \n",
       "2  delete_redir     [[WP:CSD#G6|G6]]: Deleted to make way for move   \n",
       "3        delete  content was: '==Bernard Nussbaum==Former Chief...   \n",
       "4       restore            6 revisions restored: restore for merge   \n",
       "\n",
       "  commenthidden        date       logid    logpage   ns                page  \\\n",
       "0           NaN  2008-04-13  14781556.0        0.0  0.0  Robert N. Chatigny   \n",
       "1           NaN  2009-03-05  20953870.0        0.0  0.0     John R. Tunheim   \n",
       "2           NaN  2017-01-21  80218809.0  4067205.0  0.0    Bernard Nussbaum   \n",
       "3           NaN  2005-11-26    995795.0        0.0  0.0    Bernard Nussbaum   \n",
       "4           NaN  2009-04-02  21551687.0        0.0  0.0     Sidney H. Stein   \n",
       "\n",
       "       pageid tags           timestamp               title    type  \\\n",
       "0  16729727.0   [] 2008-04-13 13:39:20  Robert N. Chatigny  patrol   \n",
       "1  21834325.0   [] 2009-03-05 23:39:29     John R. Tunheim  patrol   \n",
       "2   3040825.0   [] 2017-01-21 19:05:41    Bernard Nussbaum  delete   \n",
       "3   3040825.0   [] 2005-11-26 20:16:50    Bernard Nussbaum  delete   \n",
       "4  21832373.0   [] 2009-04-02 18:37:03     Sidney H. Stein  delete   \n",
       "\n",
       "                  user   userid  \n",
       "0  DragonflySixtyseven    62058  \n",
       "1               Polbot  4477315  \n",
       "2          Arbor to SJ  4322169  \n",
       "3            Lucky 6.9    51717  \n",
       "4               BD2412   196446  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_clinton_le_dict = {}\n",
    "all_clinton_le_error_pages = []\n",
    "\n",
    "for page in redirects_clinton_category_members:\n",
    "    try:\n",
    "        _df = get_log_events(page)\n",
    "        all_clinton_le_dict[page] = _df\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(page))\n",
    "        all_clinton_le_error_pages.append(page)\n",
    "        pass\n",
    "    \n",
    "all_trump_le_dict = {}\n",
    "all_trump_le_error_pages = []\n",
    "\n",
    "for page in redirects_trump_category_members:\n",
    "    try:\n",
    "        _df = get_log_events(page)\n",
    "        all_trump_le_dict[page] = _df\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(page))\n",
    "        all_trump_le_error_pages.append(page)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_clinton_le_df = pd.concat(all_clinton_le_dict.values(),keys=all_clinton_le_dict.keys())\n",
    "all_clinton_le_df = all_clinton_le_df.reset_index(drop=True)\n",
    "all_clinton_le_df['redirect_page'] = all_clinton_le_df['page'].map(clinton_redirect_mapping)\n",
    "all_clinton_le_df['redirect_page'].fillna(all_clinton_le_df['page'],inplace=True)\n",
    "all_clinton_le_df.to_csv('logevents_clinton.csv',encoding='utf8',index=False)\n",
    "\n",
    "all_trump_le_df = pd.concat(all_trump_le_dict.values(),keys=all_trump_le_dict.keys())\n",
    "all_trump_le_df = all_trump_le_df.reset_index(drop=True)\n",
    "all_trump_le_df['redirect_page'] = all_trump_le_df['page'].map(trump_redirect_mapping)\n",
    "all_trump_le_df['redirect_page'].fillna(all_trump_le_df['page'],inplace=True)\n",
    "all_trump_le_df.to_csv('logevents_trump.csv',encoding='utf8',index=False)\n",
    "all_trump_le_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4,464 Clinton articles (with redirects).\n",
      "There are 3,489 Trump articles (with redirects).\n"
     ]
    }
   ],
   "source": [
    "with open('clinton_category_members_redirects.json','r') as f:\n",
    "    clinton_redirect_members = json.load(f)\n",
    "    \n",
    "with open('trump_category_members_redirects.json','r') as f:\n",
    "    trump_redirect_members = json.load(f)\n",
    "    \n",
    "clinton_redirect_members_l = [r for target, redirects in clinton_redirect_members.items() for r in redirects]\n",
    "trump_redirect_members_l = [r for target, redirects in trump_redirect_members.items() for r in redirects]\n",
    "\n",
    "all_clinton_articles_w_redirects = list(set(unique_clinton_category_members) | set(clinton_redirect_members_l))\n",
    "all_trump_articles_w_redirects = list(set(unique_trump_category_members) | set(trump_redirect_members_l))\n",
    "\n",
    "print(\"There are {0:,} Clinton articles (with redirects).\\nThere are {1:,} Trump articles (with redirects).\".format(len(all_clinton_articles_w_redirects),len(all_trump_articles_w_redirects)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Temporary) Some of the names are case sensitive differences, but these case-sensitive files are over-written in the file system. Re-crawl and add some fuzz so they're not overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 490 Clinton articles and 369 Trump articles affected by case sensitivity.\n"
     ]
    }
   ],
   "source": [
    "clinton_case_sensitive = []\n",
    "trump_case_sensitive = []\n",
    "\n",
    "for a1 in all_clinton_articles_w_redirects:\n",
    "    for a2 in all_clinton_articles_w_redirects:\n",
    "        if a1.lower() == a2.lower() and a1 != a2:\n",
    "            clinton_case_sensitive.append(a1)\n",
    "            \n",
    "for a1 in all_trump_articles_w_redirects:\n",
    "    for a2 in all_trump_articles_w_redirects:\n",
    "        if a1.lower() == a2.lower() and a1 != a2:\n",
    "            trump_case_sensitive.append(a1)\n",
    "\n",
    "clinton_case_sensitive = list(set(clinton_case_sensitive))\n",
    "trump_case_sensitive = list(set(trump_case_sensitive))\n",
    "            \n",
    "print(\"There are {0:,} Clinton articles and {1:,} Trump articles affected by case sensitivity.\".format(len(clinton_case_sensitive),len(trump_case_sensitive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawl each candidate's pageview data and save it to a file (which we'll concatenate together later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clinton_error_pages = []\n",
    "\n",
    "#for i,page in enumerate(all_clinton_articles_w_redirects):\n",
    "for i,page in enumerate(clinton_case_sensitive):\n",
    "    try:\n",
    "        _df = get_pageviews(page)\n",
    "        renamed_page = quote(page.replace(' ','_').replace('/','-').replace(':','_-').replace('?',''), safe='')\n",
    "        _df.to_csv(_dir+'Data/Clinton/Pageviews/{1}-{0}.csv'.format(renamed_page,i),encoding='utf8')\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(page))\n",
    "        clinton_error_pages.append(page)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_error_pages = []\n",
    "\n",
    "#for i,page in enumerate(all_trump_articles_w_redirects):\n",
    "for i,page in enumerate(trump_case_sensitive):\n",
    "    try:\n",
    "        _df = get_pageviews(page)\n",
    "        renamed_page = quote(page.replace(' ','_').replace('/','-').replace(':','_-').replace('?',''), safe='')\n",
    "        _df.to_csv(_dir+'Data/Trump/Pageviews/{1}-{0}.csv'.format(renamed_page,i),encoding='utf8')\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(page))\n",
    "        trump_error_pages.append(page)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_pages = set(os.listdir(_dir+'/Data/Revisions')) - set(os.listdir(_dir+'/Data/Pageviews'))\n",
    "error_pages = ['/r/The Donald','American Horror Story','Bigan Kian','Fahrenheit 11/9','Trump: The Kremin Candidate','Trump: What\\'s the Deal?','Where My Country Gone']\n",
    "\n",
    "for page in error_pages:\n",
    "    try:\n",
    "        quoted_page = quote(page, safe='')\n",
    "        _df = get_pageviews(quoted_page)\n",
    "        renamed_page = page.replace(' ','_').replace('/','-').replace(':','_-').replace('?','')\n",
    "        _df.to_csv(_dir+'Data/Pageviews/{0}.csv'.format(renamed_page),encoding='utf8')\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(page))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Temporary) Clean up duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,page in enumerate(clinton_case_sensitive):\n",
    "    renamed_page = quote(page.replace(' ','_').replace('/','-').replace(':','_-').replace('?',''), safe='')\n",
    "    path = _dir+'Data/Clinton/Pageviews/{0}.csv'.format(renamed_page,i)\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "for i,page in enumerate(trump_case_sensitive):\n",
    "    renamed_page = quote(page.replace(' ','_').replace('/','-').replace(':','_-').replace('?',''), safe='')\n",
    "    path = _dir+'Data/Trump/Pageviews/{0}.csv'.format(renamed_page,i)\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">all-agents</th>\n",
       "      <th colspan=\"4\" halign=\"left\">bot</th>\n",
       "      <th colspan=\"4\" halign=\"left\">spider</th>\n",
       "      <th colspan=\"4\" halign=\"left\">user</th>\n",
       "      <th>redirected_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">\"Basket of deplorables\"</th>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   all-agents                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05       11.0    11.0        0.0        0.0   \n",
       "                        2017-06-06        2.0     2.0        0.0        0.0   \n",
       "                        2017-06-07        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-08        4.0     4.0        0.0        0.0   \n",
       "                        2017-06-09        1.0     1.0        0.0        0.0   \n",
       "\n",
       "                                          bot                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-06        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-07        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-08        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-09        0.0     0.0        0.0        0.0   \n",
       "\n",
       "                                       spider                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05        9.0     9.0        0.0        0.0   \n",
       "                        2017-06-06        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-07        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-08        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-09        1.0     1.0        0.0        0.0   \n",
       "\n",
       "                                         user                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05        2.0     2.0        0.0        0.0   \n",
       "                        2017-06-06        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-07        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-08        3.0     3.0        0.0        0.0   \n",
       "                        2017-06-09        0.0     0.0        0.0        0.0   \n",
       "\n",
       "                                            redirected_page  \n",
       "                                                             \n",
       "page                    date                                 \n",
       "\"Basket of deplorables\" 2017-06-05  \"Basket of deplorables\"  \n",
       "                        2017-06-06  \"Basket of deplorables\"  \n",
       "                        2017-06-07  \"Basket of deplorables\"  \n",
       "                        2017-06-08  \"Basket of deplorables\"  \n",
       "                        2017-06-09  \"Basket of deplorables\"  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redirects_clinton_pageview_df_list = []\n",
    "clinton_pageview_files = os.listdir(_dir+'Data/Clinton/Pageviews/')\n",
    "\n",
    "for f in clinton_pageview_files:\n",
    "    try:\n",
    "        df = pd.read_csv(_dir + 'Data/Clinton/Pageviews/{0}'.format(f),engine='python',header=[0,1],skiprows=[2],index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)        \n",
    "        df[('page','page')] = df[('page','page')].apply(lambda x:unquote(x))\n",
    "        df[('redirected_page','')] = df[('page','page')]\n",
    "        redirects_clinton_pageview_df_list.append(df)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(f))\n",
    "        pass\n",
    "    \n",
    "redirects_clinton_pageviews_df = pd.concat(redirects_clinton_pageview_df_list)\n",
    "redirects_clinton_pageviews_df = redirects_clinton_pageviews_df.reset_index().set_index([('page','page'),('index','')])\n",
    "redirects_clinton_pageviews_df.index.names = ['page','date']\n",
    "redirects_clinton_pageviews_df.columns.names = ['','']\n",
    "redirects_clinton_pageviews_df.to_csv('redirects_clinton_pageviews.csv',encoding='utf8')\n",
    "redirects_clinton_pageviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">all-agents</th>\n",
       "      <th colspan=\"4\" halign=\"left\">bot</th>\n",
       "      <th colspan=\"4\" halign=\"left\">spider</th>\n",
       "      <th colspan=\"4\" halign=\"left\">user</th>\n",
       "      <th>redirected_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th>all-access</th>\n",
       "      <th>desktop</th>\n",
       "      <th>mobile-app</th>\n",
       "      <th>mobile-web</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">\"Basket of deplorables\"</th>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"Basket of deplorables\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   all-agents                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05       11.0    11.0        0.0        0.0   \n",
       "                        2017-06-06        2.0     2.0        0.0        0.0   \n",
       "                        2017-06-07        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-08        4.0     4.0        0.0        0.0   \n",
       "                        2017-06-09        1.0     1.0        0.0        0.0   \n",
       "\n",
       "                                          bot                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-06        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-07        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-08        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-09        0.0     0.0        0.0        0.0   \n",
       "\n",
       "                                       spider                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05        9.0     9.0        0.0        0.0   \n",
       "                        2017-06-06        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-07        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-08        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-09        1.0     1.0        0.0        0.0   \n",
       "\n",
       "                                         user                                \\\n",
       "                                   all-access desktop mobile-app mobile-web   \n",
       "page                    date                                                  \n",
       "\"Basket of deplorables\" 2017-06-05        2.0     2.0        0.0        0.0   \n",
       "                        2017-06-06        1.0     1.0        0.0        0.0   \n",
       "                        2017-06-07        0.0     0.0        0.0        0.0   \n",
       "                        2017-06-08        3.0     3.0        0.0        0.0   \n",
       "                        2017-06-09        0.0     0.0        0.0        0.0   \n",
       "\n",
       "                                            redirected_page  \n",
       "                                                             \n",
       "page                    date                                 \n",
       "\"Basket of deplorables\" 2017-06-05  \"Basket of deplorables\"  \n",
       "                        2017-06-06  \"Basket of deplorables\"  \n",
       "                        2017-06-07  \"Basket of deplorables\"  \n",
       "                        2017-06-08  \"Basket of deplorables\"  \n",
       "                        2017-06-09  \"Basket of deplorables\"  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redirects_trump_pageview_df_list = []\n",
    "trump_pageview_files = os.listdir(_dir+'Data/Trump/Pageviews/')\n",
    "\n",
    "for f in trump_pageview_files:\n",
    "    try:\n",
    "        df = pd.read_csv(_dir + 'Data/Trump/Pageviews/{0}'.format(f),engine='python',header=[0,1],skiprows=[2],index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df[('page','page')] = df[('page','page')].apply(lambda x:unquote(x))\n",
    "        df[('redirected_page','')] = df[('page','page')]\n",
    "        redirects_trump_pageview_df_list.append(df)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(\"Error on \\\"{0}\\\"\".format(f))\n",
    "        pass\n",
    "    \n",
    "redirects_trump_pageviews_df = pd.concat(redirects_trump_pageview_df_list)\n",
    "redirects_trump_pageviews_df = redirects_trump_pageviews_df.reset_index().set_index([('page','page'),('index','')])\n",
    "redirects_trump_pageviews_df.index.names = ['page','date']\n",
    "redirects_trump_pageviews_df.columns.names = ['','']\n",
    "redirects_trump_pageviews_df.to_csv('redirects_trump_pageviews.csv',encoding='utf8')\n",
    "redirects_trump_pageviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the pageviews from the redirects to the parent article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clinton_redirects_mapping = {} \n",
    "for target,redirects in clinton_redirect_members.items():\n",
    "    clinton_redirects_mapping[target] = target\n",
    "    for r in redirects:\n",
    "        clinton_redirects_mapping[r] = target\n",
    "        \n",
    "trump_redirects_mapping = {}\n",
    "for target,redirects in trump_redirect_members.items():\n",
    "    trump_redirects_mapping[target] = target\n",
    "    for r in redirects:\n",
    "        trump_redirects_mapping[r] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#redirects_clinton_pageviews_df['redirected_page'] = redirects_clinton_pageviews_df.reset_index(0)[('page','')].values\n",
    "#redirects_trump_pageviews_df['redirected_page'] = redirects_trump_pageviews_df.reset_index(0)[('page','')].values\n",
    "\n",
    "redirects_clinton_pageviews_df['redirected_page'] = redirects_clinton_pageviews_df['redirected_page'].map(clinton_redirects_mapping)\n",
    "redirects_trump_pageviews_df['redirected_page'] = redirects_trump_pageviews_df['redirected_page'].map(trump_redirects_mapping)\n",
    "\n",
    "pv_columns = redirects_clinton_pageviews_df.columns.get_values()[:-1]\n",
    "agg_func = dict(zip(pv_columns,[np.sum]*len(pv_columns)))\n",
    "\n",
    "combined_clinton_pageviews_df = redirects_clinton_pageviews_df.reset_index().groupby([('redirected_page',''),('date','')]).agg(agg_func)\n",
    "combined_trump_pageviews_df = redirects_trump_pageviews_df.reset_index().groupby([('redirected_page',''),('date','')]).agg(agg_func)\n",
    "\n",
    "combined_clinton_pageviews_df.index.names = ['page','date']\n",
    "combined_trump_pageviews_df.index.names = ['page','date']\n",
    "\n",
    "combined_clinton_pageviews_df.to_csv('all_clinton_pageviews_redirects.csv',encoding='utf8')\n",
    "combined_trump_pageviews_df.to_csv('all_trump_pageviews_redirects.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The July 1, 2015 number should be north of 11,000 -- if it's not, we lost the main Hillary Clinton article somewhere along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2015-07-01    13624.0\n",
       "2015-07-02    12686.0\n",
       "2015-07-03    11251.0\n",
       "2015-07-04    10373.0\n",
       "2015-07-05    11907.0\n",
       "Name: (all-agents, all-access), dtype: float64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_clinton_pageviews_df.loc['Hillary Clinton',('all-agents','all-access')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2015-07-01    89519.0\n",
       "2015-07-02    90804.0\n",
       "2015-07-03    60450.0\n",
       "2015-07-04    47489.0\n",
       "2015-07-05    45924.0\n",
       "Name: (all-agents, all-access), dtype: float64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_trump_pageviews_df.loc['Donald Trump',('all-agents','all-access')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revision content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find the revision id for each date that is closest in value to the median length of the article on that day. The goal here is to find a \"typical\" revision for that day by ignoring vandalism or other anomalous edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page                          date      \n",
       "104th United States Congress  2004-02-05    2322487\n",
       "                              2004-02-07    2348088\n",
       "                              2004-02-09    2547608\n",
       "                              2004-02-27    2915574\n",
       "                              2004-03-25    3475257\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closest_revid_to_median_size(_df):\n",
    "    # https://stackoverflow.com/questions/30112202/how-do-i-find-the-closest-values-in-a-pandas-series-to-an-input-number\n",
    "    return _df.iloc[(_df['size']-_df['size'].median()).abs().argsort()]['revid'].values[0]\n",
    "\n",
    "closest_revid_to_median_size_df = all_page_revisions_df.groupby(['page','date']).apply(closest_revid_to_median_size)\n",
    "closest_revid_to_median_size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,720 daily revisions for \"Hillary Clinton\"\n"
     ]
    }
   ],
   "source": [
    "#median_trump_revids = closest_revid_to_median_size_df.loc['Donald Trump'].apply(str).to_dict()\n",
    "median_clinton_revids = closest_revid_to_median_size_df.loc['Hillary Clinton'].apply(str).to_dict()\n",
    "\n",
    "median_clinton_revids = {str(date.date()):revid for date,revid in median_clinton_revids.items()}\n",
    "\n",
    "#print(\"There are {0:,} daily revisions for \\\"Donald Trump\\\"\".format(len(median_trump_revids)))\n",
    "print(\"There are {0:,} daily revisions for \\\"Hillary Clinton\\\"\".format(len(median_clinton_revids)))\n",
    "\n",
    "with open('median_clinton_revids.json','w') as f:\n",
    "    json.dump(median_clinton_revids,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, pull the revision content (outlinks, external links, markup *etc.*) for each of these revisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-08-01    256189\n",
       "2001-12-07    256190\n",
       "2002-02-25     72270\n",
       "2002-05-18     72370\n",
       "2002-07-07    112733\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(median_clinton_revids).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for date,revid in median_trump_revids.items():\n",
    "for date,revid in median_clinton_revids.items():\n",
    "    #_d = {'date':date,'revid':revid,'page':'Donald Trump'}\n",
    "    _d = {'date':date,'revid':revid,'page':'Hillary Clinton'}\n",
    "    _d['content'] = get_rev_content(revid)\n",
    "    with open(_dir+'Data/Clinton/Content/{0}.json'.format(revid),'w') as f:\n",
    "        json.dump(_d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for date,revid in median_trump_revids.items():\n",
    "current_revids = [revid[:-5] for revid in os.listdir(_dir+'Data/Clinton/Links/')]\n",
    "for date,revid in median_clinton_revids.items():\n",
    "    #_d = {'date':date,'revid':revid,'page':'Donald Trump'}\n",
    "    if revid not in current_revids:\n",
    "        _d = {'date':date,'revid':revid,'page':'Hillary Clinton'}\n",
    "        _d['links'] = get_rev_outlinks(revid)\n",
    "        time.sleep(1)\n",
    "        with open(_dir+'Data/Clinton/Links/{0}.json'.format(revid),'w') as f:\n",
    "            json.dump(_d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#current_revids = [revid[:-5] for revid in os.listdir(_dir+'Data/Trump/Markup/')]\n",
    "#for date,revid in median_trump_revids.items():\n",
    "\n",
    "current_revids = [revid[:-5] for revid in os.listdir(_dir+'Data/Clinton/Markup/')]\n",
    "for date,revid in median_clinton_revids.items():\n",
    "    \n",
    "    if revid not in current_revids:\n",
    "        #_d = {'date':date,'revid':revid,'page':'Donald Trump'}\n",
    "        _d = {'date':date,'revid':revid,'page':'Hillary Clinton'}\n",
    "        _d['markup'] = get_rev_markup(revid)\n",
    "        time.sleep(1)\n",
    "        with open(_dir+'Data/Clinton/Markup/{0}.json'.format(revid),'w') as f:\n",
    "            json.dump(_d,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all revisions for year before and after election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start, stop = pd.Timestamp('2015-11-07'), pd.Timestamp('2017-11-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_trump_rev_df = pd.read_csv('all_trump_page_revisions.csv',low_memory=False,parse_dates=['date','timestamp'])\n",
    "all_clinton_rev_df = pd.read_csv('all_clinton_page_revisions.csv',low_memory=False,parse_dates=['date','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13,970 revisions on the \"Donald Trump\" article over the year preceding and following the election\n",
      "There are 2,667 revisions on the \"Hillary Clinton\" article over the year preceding and following the election\n"
     ]
    }
   ],
   "source": [
    "trump_rev_df = all_trump_rev_df[all_trump_rev_df['page'] == \"Donald Trump\"]\n",
    "hillary_rev_df = all_clinton_rev_df[all_clinton_rev_df['page'] == \"Hillary Clinton\"]\n",
    "\n",
    "trump_rev_df = trump_rev_df[(trump_rev_df['date'] > start) & (trump_rev_df['date'] < stop)]\n",
    "hillary_rev_df = hillary_rev_df[(hillary_rev_df['date'] > start) & (hillary_rev_df['date'] < stop)]\n",
    "\n",
    "print(\"There are {0:,} revisions on the \\\"Donald Trump\\\" article over the year preceding and following the election\".format(len(trump_rev_df)))\n",
    "print(\"There are {0:,} revisions on the \\\"Hillary Clinton\\\" article over the year preceding and following the election\".format(len(hillary_rev_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12,800 unique revisions on the \"Donald Trump\" article over the year preceding and following the election\n",
      "There are 2,216 unique revisions on the \"Hillary Clinton\" article over the year preceding and following the election\n"
     ]
    }
   ],
   "source": [
    "unique_trump_revids = list(trump_rev_df.groupby('sha1').agg({'revid':lambda x:list(x)[0]})['revid'].values)\n",
    "unique_hillary_revids = list(hillary_rev_df.groupby('sha1').agg({'revid':lambda x:list(x)[0]})['revid'].values)\n",
    "print(\"There are {0:,} unique revisions on the \\\"Donald Trump\\\" article over the year preceding and following the election\".format(len(unique_trump_revids)))\n",
    "print(\"There are {0:,} unique revisions on the \\\"Hillary Clinton\\\" article over the year preceding and following the election\".format(len(unique_hillary_revids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_hillary_revids = [revid[:-5] for revid in os.listdir(_dir+'Data/Clinton/Markup/')]\n",
    "for revid in unique_hillary_revids:   \n",
    "    if revid not in current_hillary_revids:\n",
    "        date = str(pd.to_datetime(hillary_rev_df[hillary_rev_df['revid'] == revid]['date'].values[0]).date())\n",
    "        _d = {'date':date,'revid':int(revid),'page':'Hillary Clinton'}\n",
    "        _d['markup'] = get_rev_markup(revid)\n",
    "        time.sleep(.5)\n",
    "        with open(_dir+'Data/Clinton/Markup/{0}.json'.format(revid),'w') as f:\n",
    "            json.dump(_d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_trump_revids = [revid[:-5] for revid in os.listdir(_dir+'Data/Trump/Markup/')]\n",
    "for revid in unique_trump_revids:\n",
    "    if revid not in current_trump_revids:\n",
    "        date = str(pd.to_datetime(trump_rev_df[trump_rev_df['revid'] == revid]['date'].values[0]).date())\n",
    "        _d = {'date':date,'revid':int(revid),'page':'Donald Trump'}\n",
    "        _d['markup'] = get_rev_markup(revid)\n",
    "        time.sleep(.5)\n",
    "        with open(_dir+'Data/Trump/Markup/{0}.json'.format(revid),'w') as f:\n",
    "            json.dump(_d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
